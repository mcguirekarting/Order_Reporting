{"file_contents":{"utils/create_admin_user.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nInitial User Setup Script\nCreates the first admin user for the reporting system\nRun this after setting up the database schema\n\"\"\"\n\nimport sys\nimport os\nimport getpass\n\n# Add utils directory to path\nsys.path.append('/opt/airflow')\n\nfrom utils.user_management import create_user, get_user_info\n\n\ndef create_admin_user():\n    \"\"\"\n    Interactive script to create the first admin user\n    \"\"\"\n    print(\"=\" * 60)\n    print(\"Report Microservice - Initial Admin User Setup\")\n    print(\"=\" * 60)\n    print()\n    \n    # Get user input\n    username = input(\"Enter admin username: \").strip()\n    if not username:\n        print(\"ERROR: Username is required\")\n        return False\n    \n    email = input(\"Enter admin email: \").strip()\n    if not email:\n        print(\"ERROR: Email is required\")\n        return False\n    \n    first_name = input(\"Enter first name (optional): \").strip() or None\n    last_name = input(\"Enter last name (optional): \").strip() or None\n    \n    # Get password with confirmation\n    while True:\n        password = getpass.getpass(\"Enter password: \")\n        if not password:\n            print(\"ERROR: Password is required\")\n            continue\n        \n        password_confirm = getpass.getpass(\"Confirm password: \")\n        \n        if password != password_confirm:\n            print(\"ERROR: Passwords do not match. Please try again.\")\n            continue\n        \n        break\n    \n    print()\n    print(\"Creating admin user...\")\n    \n    try:\n        # Create the user with ADMIN role\n        user_id = create_user(\n            username=username,\n            email=email,\n            password=password,\n            first_name=first_name,\n            last_name=last_name,\n            roles=['ADMIN'],\n            created_by='SYSTEM',\n            must_change_password=False\n        )\n        \n        if user_id:\n            print()\n            print(\"=\" * 60)\n            print(\"SUCCESS! Admin user created successfully\")\n            print(\"=\" * 60)\n            print(f\"User ID: {user_id}\")\n            print(f\"Username: {username}\")\n            print(f\"Email: {email}\")\n            print(f\"Role: ADMIN\")\n            print()\n            print(\"You can now log in to the system with these credentials.\")\n            print(\"=\" * 60)\n            return True\n        else:\n            print()\n            print(\"ERROR: Failed to create admin user\")\n            print(\"Please check the logs for more details\")\n            return False\n            \n    except Exception as e:\n        print()\n        print(f\"ERROR: An exception occurred: {str(e)}\")\n        return False\n\n\ndef create_sample_users():\n    \"\"\"\n    Create sample users for testing (optional)\n    \"\"\"\n    print()\n    create_samples = input(\"Would you like to create sample test users? (y/n): \").strip().lower()\n    \n    if create_samples != 'y':\n        return\n    \n    print(\"\\nCreating sample users...\")\n    \n    sample_users = [\n        {\n            'username': 'report_manager',\n            'email': 'manager@example.com',\n            'password': 'Manager123!',\n            'first_name': 'Report',\n            'last_name': 'Manager',\n            'roles': ['REPORT_MANAGER']\n        },\n        {\n            'username': 'report_viewer',\n            'email': 'viewer@example.com',\n            'password': 'Viewer123!',\n            'first_name': 'Report',\n            'last_name': 'Viewer',\n            'roles': ['REPORT_VIEWER']\n        },\n        {\n            'username': 'report_executor',\n            'email': 'executor@example.com',\n            'password': 'Executor123!',\n            'first_name': 'Report',\n            'last_name': 'Executor',\n            'roles': ['REPORT_EXECUTOR']\n        }\n    ]\n    \n    for user_data in sample_users:\n        try:\n            user_id = create_user(\n                username=user_data['username'],\n                email=user_data['email'],\n                password=user_data['password'],\n                first_name=user_data['first_name'],\n                last_name=user_data['last_name'],\n                roles=user_data['roles'],\n                created_by='SYSTEM'\n            )\n            \n            if user_id:\n                print(f\"✓ Created user: {user_data['username']} (Role: {user_data['roles'][0]})\")\n            else:\n                print(f\"✗ Failed to create user: {user_data['username']}\")\n        except Exception as e:\n            print(f\"✗ Error creating user {user_data['username']}: {str(e)}\")\n    \n    print(\"\\nSample users created!\")\n    print(\"\\nTest Credentials:\")\n    print(\"-\" * 40)\n    for user_data in sample_users:\n        print(f\"Username: {user_data['username']}\")\n        print(f\"Password: {user_data['password']}\")\n        print(f\"Role: {user_data['roles'][0]}\")\n        print(\"-\" * 40)\n\n\nif __name__ == \"__main__\":\n    try:\n        # Create admin user\n        success = create_admin_user()\n        \n        if success:\n            # Optionally create sample users\n            create_sample_users()\n        \n        sys.exit(0 if success else 1)\n        \n    except KeyboardInterrupt:\n        print(\"\\n\\nSetup cancelled by user\")\n        sys.exit(1)\n    except Exception as e:\n        print(f\"\\n\\nUnexpected error: {str(e)}\")\n        import traceback\n        traceback.print_exc()\n        sys.exit(1)\n","size_bytes":5296},"README.Docker.md":{"content":"### Building and running your application\n\nWhen you're ready, start your application by running:\n`docker compose up --build`.\n\nYour application will be available at http://localhost:8080.\n\n### Deploying your application to the cloud\n\nFirst, build your image, e.g.: `docker build -t myapp .`.\nIf your cloud uses a different CPU architecture than your development\nmachine (e.g., you are on a Mac M1 and your cloud provider is amd64),\nyou'll want to build the image for that platform, e.g.:\n`docker build --platform=linux/amd64 -t myapp .`.\n\nThen, push it to your registry, e.g. `docker push myregistry.com/myapp`.\n\nConsult Docker's [getting started](https://docs.docker.com/go/get-started-sharing/)\ndocs for more detail on building and pushing.\n\n### References\n* [Docker's Python guide](https://docs.docker.com/language/python/)","size_bytes":826},"docker-compose.yaml":{"content":"version: '3.8'\n\nx-airflow-common:\n  &airflow-common\n  image: apache/airflow:2.7.2-python3.9\n  environment:\n    &airflow-common-env\n    AIRFLOW__CORE__SQL_ALCHEMY_CONN: sqlite:////airflow/airflow.db\n    AIRFLOW__CORE__EXECUTOR: LocalExecutor\n    AIRFLOW__CORE__FERNET_KEY: ''\n    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'\n    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'\n    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'\n    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'\n    \n    # Email configuration\n    AIRFLOW__SMTP__SMTP_HOST: ${SMTP_HOST:-smtp.gmail.com}\n    AIRFLOW__SMTP__SMTP_PORT: ${SMTP_PORT:-587}\n    AIRFLOW__SMTP__SMTP_USER: ${SMTP_USER:-your-email@gmail.com}\n    AIRFLOW__SMTP__SMTP_PASSWORD: ${SMTP_PASSWORD:-your-password}\n    AIRFLOW__SMTP__SMTP_MAIL_FROM: ${SMTP_MAIL_FROM:-your-email@gmail.com}\n    AIRFLOW__SMTP__SMTP_STARTTLS: 'True'\n    AIRFLOW__SMTP__SMTP_SSL: 'False'\n    \n    # API connection\n    ORDER_API_BASE_URL: ${ORDER_API_BASE_URL:-https://api.example.com}\n    ORDER_API_CLIENT_ID: ${ORDER_API_CLIENT_ID:-default_client_id}\n    ORDER_API_CLIENT_SECRET: ${ORDER_API_CLIENT_SECRET:-default_client_secret}\n    \n    # MongoDB connection\n    MONGODB_CONNECTION_STRING: mongodb://mongodb:27017/\n    MONGODB_DATABASE: order_reports\n    MONGODB_COLLECTION: api_responses\n    \n    # Oracle Database connection\n    ORACLE_USER: ${ORACLE_USER:-report_user}\n    ORACLE_PASSWORD: ${ORACLE_PASSWORD:-report_password}\n    ORACLE_HOST: oracle-db\n    ORACLE_PORT: 1521\n    ORACLE_SERVICE: ${ORACLE_SERVICE:-XEPDB1}\n    \n  volumes:\n    - ./dags:/opt/airflow/dags\n    - ./logs:/opt/airflow/logs\n    - ./config:/opt/airflow/config\n    - ./plugins:/opt/airflow/plugins\n    - ./utils:/opt/airflow/utils\n    - ./tmp:/tmp\n    - ./airflow:/airflow\n  depends_on:\n    - mongodb\n    - oracle-db\n  \nservices:\n  # Oracle Database - FIXED ENVIRONMENT SECTION\n  oracle-db:\n    image: gvenzl/oracle-xe:21-slim\n    container_name: oracle-reports-db\n    environment:\n      ORACLE_PASSWORD: ${ORACLE_PASSWORD:-report_password}\n      ORACLE_DATABASE: ${ORACLE_DATABASE:-REPORTS}\n      APP_USER: ${ORACLE_USER:-report_user}\n      APP_USER_PASSWORD: ${ORACLE_PASSWORD:-report_password}\n    ports:\n      - \"1521:1521\"\n      - \"5500:5500\"\n    volumes:\n      - oracle_data:/opt/oracle/oradata\n      - ./init-scripts:/container-entrypoint-initdb.d\n    healthcheck:\n      test: [\"CMD\", \"healthcheck.sh\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n    restart: always\n\n  # MongoDB\n  mongodb:\n    image: mongo:latest\n    container_name: mongodb-reports\n    ports:\n      - \"27017:27017\"\n    volumes:\n      - mongodb_data:/data/db\n    environment:\n      MONGO_INITDB_DATABASE: order_reports\n    healthcheck:\n      test: echo 'db.runCommand(\"ping\").ok' | mongosh localhost:27017/order_reports --quiet\n      interval: 10s\n      timeout: 10s\n      retries: 5\n    restart: always\n    \n  # Airflow Init\n  airflow-init:\n    <<: *airflow-common\n    entrypoint: /bin/bash\n    command: >\n      -c \"\n        pip install pymongo pandas matplotlib reportlab requests oracledb bcrypt\n        pip install 'apache-airflow-providers-openlineage>=1.8.0' --no-deps\n        mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins /opt/airflow/config /opt/airflow/utils /tmp /airflow\n        airflow db init\n        airflow db upgrade\n        if ! airflow users list | grep -q 'admin'; then\n          airflow users create -r Admin -u admin -p admin -e admin@example.com -f Admin -l User\n        fi\n        exit 0 \n      \"\n    restart: on-failure\n\n  # Airflow Webserver\n  airflow-webserver:\n    <<: *airflow-common\n    container_name: airflow-webserver\n    depends_on:\n      - airflow-init\n      - mongodb\n      - oracle-db\n    command: >\n      bash -c \"\n        pip install pymongo pandas matplotlib reportlab requests oracledb\n        pip install 'apache-airflow-providers-openlineage>=1.8.0' --no-deps\n        exec airflow webserver\n      \"\n    ports:\n      - \"8080:8080\"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"--fail\", \"http://localhost:8080/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n    restart: always\n\n  # Airflow Scheduler\n  airflow-scheduler:\n    <<: *airflow-common\n    container_name: airflow-scheduler\n    depends_on:\n      - airflow-init\n      - mongodb\n      - oracle-db\n    command: >\n      bash -c \"\n        pip install pymongo pandas matplotlib reportlab requests oracledb\n        pip install 'apache-airflow-providers-openlineage>=1.8.0' --no-deps\n        exec airflow scheduler\n      \"\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"--fail\", \"http://localhost:8974/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n    restart: always\n    \n  # MongoDB Admin Interface\n  mongo-express:\n    image: mongo-express:latest\n    container_name: mongo-express\n    restart: always\n    ports:\n      - \"8081:8081\"\n    environment:\n      ME_CONFIG_MONGODB_SERVER: mongodb\n      ME_CONFIG_MONGODB_PORT: 27017\n      ME_CONFIG_BASICAUTH_USERNAME: admin\n      ME_CONFIG_BASICAUTH_PASSWORD: admin\n    depends_on:\n      - mongodb\n\nvolumes:\n  mongodb_data:\n    driver: local\n  oracle_data:\n    driver: local","size_bytes":5161},"utils/oracle_db_utils.py":{"content":"\"\"\"\nOracle Database Utilities for Report Microservice\nProvides functions to interact with the report database\n\"\"\"\n\nimport json\nimport logging\nimport os\nfrom datetime import datetime\nfrom typing import List, Dict, Any, Optional\nimport oracledb\nfrom airflow.models import Variable\n\nlogger = logging.getLogger(\"oracle_db_utils\")\n\n\ndef get_db_connection():\n    \"\"\"\n    Get an Oracle database connection using credentials from environment or Airflow variables\n    \n    Returns:\n        oracledb.Connection: Database connection object\n    \"\"\"\n    try:\n        # Get connection details from environment or Airflow variables\n        db_user = os.environ.get(\"ORACLE_USER\", Variable.get(\"oracle_user\", \"report_user\"))\n        db_password = os.environ.get(\"ORACLE_PASSWORD\", Variable.get(\"oracle_password\", \"your_secure_password\"))\n        db_host = os.environ.get(\"ORACLE_HOST\", Variable.get(\"oracle_host\", \"localhost\"))\n        db_port = os.environ.get(\"ORACLE_PORT\", Variable.get(\"oracle_port\", \"1521\"))\n        db_service = os.environ.get(\"ORACLE_SERVICE\", Variable.get(\"oracle_service\", \"ORCL\"))\n        \n        # Create DSN\n        dsn = oracledb.makedsn(db_host, db_port, service_name=db_service)\n        \n        # Create connection\n        connection = oracledb.connect(user=db_user, password=db_password, dsn=dsn)\n        \n        logger.info(f\"Successfully connected to Oracle database: {db_host}:{db_port}/{db_service}\")\n        return connection\n        \n    except oracledb.Error as error:\n        logger.error(f\"Error connecting to Oracle database: {error}\")\n        raise\n\n\ndef get_report_config(report_id: str) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Retrieve a report configuration from the database\n    \n    Args:\n        report_id: The report ID to retrieve\n        \n    Returns:\n        Dictionary containing the report configuration or None if not found\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        # Get main report config\n        cursor.execute(\"\"\"\n            SELECT report_id, report_name, description, schedule_cron, \n                   view_name, order_type, sort_field, is_active\n            FROM report_configs\n            WHERE report_id = :report_id AND is_active = 1\n        \"\"\", report_id=report_id)\n        \n        row = cursor.fetchone()\n        if not row:\n            logger.warning(f\"Report config not found for report_id: {report_id}\")\n            return None\n        \n        config = {\n            \"report_id\": row[0],\n            \"name\": row[1],\n            \"description\": row[2],\n            \"schedule\": row[3],\n            \"query_parameters\": {\n                \"view_name\": row[4],\n                \"order_type\": row[5],\n                \"sort_field\": row[6]\n            }\n        }\n        \n        # Get report fields\n        cursor.execute(\"\"\"\n            SELECT field_name, field_label, field_order\n            FROM report_fields\n            WHERE report_id = :report_id\n            ORDER BY field_order\n        \"\"\", report_id=report_id)\n        \n        config[\"report_fields\"] = [row[0] for row in cursor.fetchall()]\n        \n        # Get summary fields\n        cursor.execute(\"\"\"\n            SELECT field_name, operation, label, summary_order\n            FROM report_summary_fields\n            WHERE report_id = :report_id\n            ORDER BY summary_order\n        \"\"\", report_id=report_id)\n        \n        config[\"summary_fields\"] = [\n            {\"field\": row[0], \"operation\": row[1], \"label\": row[2]}\n            for row in cursor.fetchall()\n        ]\n        \n        # Get recipients\n        cursor.execute(\"\"\"\n            SELECT email_address, recipient_type\n            FROM report_recipients\n            WHERE report_id = :report_id AND is_active = 1\n        \"\"\", report_id=report_id)\n        \n        recipients = cursor.fetchall()\n        config[\"email\"] = {\n            \"recipients\": [row[0] for row in recipients if row[1] == 'TO'],\n            \"cc\": [row[0] for row in recipients if row[1] == 'CC'],\n            \"bcc\": [row[0] for row in recipients if row[1] == 'BCC']\n        }\n        \n        cursor.close()\n        return config\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error retrieving report config: {error}\")\n        return None\n    finally:\n        if connection:\n            connection.close()\n\n\ndef get_active_report_ids() -> List[str]:\n    \"\"\"\n    Get list of all active report IDs\n    \n    Returns:\n        List of active report IDs\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        cursor.execute(\"\"\"\n            SELECT report_id\n            FROM report_configs\n            WHERE is_active = 1\n            ORDER BY report_id\n        \"\"\")\n        \n        report_ids = [row[0] for row in cursor.fetchall()]\n        cursor.close()\n        \n        logger.info(f\"Retrieved {len(report_ids)} active reports\")\n        return report_ids\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error retrieving active reports: {error}\")\n        return []\n    finally:\n        if connection:\n            connection.close()\n\n\ndef start_report_execution(report_id: str, from_date: datetime, to_date: datetime,\n                          dag_run_id: str = None) -> Optional[int]:\n    \"\"\"\n    Log the start of a report execution\n    \n    Args:\n        report_id: The report ID being executed\n        from_date: Start date for the report data\n        to_date: End date for the report data\n        dag_run_id: Optional Airflow DAG run ID\n        \n    Returns:\n        Execution ID if successful, None otherwise\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        cursor.execute(\"\"\"\n            INSERT INTO report_execution_history \n                (report_id, execution_date, start_time, status, from_date, to_date, airflow_dag_run_id)\n            VALUES \n                (:report_id, SYSTIMESTAMP, SYSTIMESTAMP, 'RUNNING', :from_date, :to_date, :dag_run_id)\n            RETURNING execution_id INTO :exec_id\n        \"\"\", report_id=report_id, from_date=from_date, to_date=to_date, \n             dag_run_id=dag_run_id, exec_id=cursor.var(oracledb.NUMBER))\n        \n        execution_id = cursor.getvalue(0)\n        connection.commit()\n        cursor.close()\n        \n        logger.info(f\"Started execution {execution_id} for report {report_id}\")\n        return int(execution_id)\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error starting execution: {error}\")\n        if connection:\n            connection.rollback()\n        return None\n    finally:\n        if connection:\n            connection.close()\n\n\ndef complete_report_execution(execution_id: int, status: str, records_processed: int = None,\n                              error_message: str = None, pdf_file_path: str = None,\n                              mongodb_doc_id: str = None):\n    \"\"\"\n    Mark a report execution as complete\n    \n    Args:\n        execution_id: The execution ID to update\n        status: Final status ('SUCCESS', 'FAILED', 'CANCELLED')\n        records_processed: Number of records processed\n        error_message: Error message if failed\n        pdf_file_path: Path to generated PDF file\n        mongodb_doc_id: MongoDB document ID if logged\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        cursor.execute(\"\"\"\n            UPDATE report_execution_history\n            SET end_time = SYSTIMESTAMP,\n                status = :status,\n                records_processed = :records_processed,\n                error_message = :error_message,\n                pdf_file_path = :pdf_file_path,\n                mongodb_doc_id = :mongodb_doc_id\n            WHERE execution_id = :execution_id\n        \"\"\", execution_id=execution_id, status=status, records_processed=records_processed,\n             error_message=error_message, pdf_file_path=pdf_file_path, \n             mongodb_doc_id=mongodb_doc_id)\n        \n        connection.commit()\n        cursor.close()\n        \n        logger.info(f\"Completed execution {execution_id} with status {status}\")\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error completing execution: {error}\")\n        if connection:\n            connection.rollback()\n    finally:\n        if connection:\n            connection.close()\n\n\ndef cache_api_response(report_id: str, execution_id: int, from_date: datetime,\n                      to_date: datetime, view_name: str, order_type: str,\n                      response_data: List[Dict], mongodb_doc_id: str = None):\n    \"\"\"\n    Cache an API response in the database\n    \n    Args:\n        report_id: Report ID\n        execution_id: Execution ID\n        from_date: Start date of query\n        to_date: End date of query\n        view_name: View name used in query\n        order_type: Order type used in query\n        response_data: The API response data\n        mongodb_doc_id: MongoDB document ID if also logged there\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        # Convert response data to JSON string\n        response_json = json.dumps(response_data)\n        \n        # Get cache expiry from config (default 24 hours)\n        cache_hours = int(Variable.get(\"cache_expiry_hours\", \"24\"))\n        \n        cursor.execute(\"\"\"\n            INSERT INTO api_response_cache \n                (report_id, execution_id, request_timestamp, from_date, to_date,\n                 view_name, order_type, response_status, record_count, response_data,\n                 mongodb_doc_id, cache_expiry)\n            VALUES \n                (:report_id, :execution_id, SYSTIMESTAMP, :from_date, :to_date,\n                 :view_name, :order_type, 200, :record_count, :response_data,\n                 :mongodb_doc_id, SYSTIMESTAMP + INTERVAL :cache_hours HOUR)\n        \"\"\", report_id=report_id, execution_id=execution_id, from_date=from_date,\n             to_date=to_date, view_name=view_name, order_type=order_type,\n             record_count=len(response_data), response_data=response_json,\n             mongodb_doc_id=mongodb_doc_id, cache_hours=str(cache_hours))\n        \n        connection.commit()\n        cursor.close()\n        \n        logger.info(f\"Cached API response for execution {execution_id}\")\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error caching API response: {error}\")\n        if connection:\n            connection.rollback()\n    finally:\n        if connection:\n            connection.close()\n\n\ndef log_email_delivery(execution_id: int, recipient_email: str, delivery_status: str,\n                       email_subject: str = None, attachment_size: int = None,\n                       error_message: str = None):\n    \"\"\"\n    Log an email delivery attempt\n    \n    Args:\n        execution_id: The execution ID\n        recipient_email: Email address of recipient\n        delivery_status: Status ('PENDING', 'SENT', 'FAILED', 'BOUNCED')\n        email_subject: Email subject line\n        attachment_size: Size of attachment in bytes\n        error_message: Error message if failed\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        cursor.execute(\"\"\"\n            INSERT INTO email_delivery_log \n                (execution_id, recipient_email, send_timestamp, delivery_status,\n                 email_subject, attachment_size, error_message)\n            VALUES \n                (:execution_id, :recipient_email, SYSTIMESTAMP, :delivery_status,\n                 :email_subject, :attachment_size, :error_message)\n        \"\"\", execution_id=execution_id, recipient_email=recipient_email,\n             delivery_status=delivery_status, email_subject=email_subject,\n             attachment_size=attachment_size, error_message=error_message)\n        \n        connection.commit()\n        cursor.close()\n        \n        logger.info(f\"Logged email delivery to {recipient_email} with status {delivery_status}\")\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error logging email delivery: {error}\")\n        if connection:\n            connection.rollback()\n    finally:\n        if connection:\n            connection.close()\n\n\ndef log_error(report_id: str = None, execution_id: int = None, error_source: str = None,\n              error_type: str = None, error_message: str = None, stack_trace: str = None,\n              dag_id: str = None, task_id: str = None):\n    \"\"\"\n    Log an error to the centralized error log\n    \n    Args:\n        report_id: Report ID if applicable\n        execution_id: Execution ID if applicable\n        error_source: Source of the error (e.g., 'API', 'PDF_GENERATION', 'EMAIL')\n        error_type: Type of error (e.g., 'ConnectionError', 'ValidationError')\n        error_message: Error message\n        stack_trace: Full stack trace\n        dag_id: Airflow DAG ID\n        task_id: Airflow task ID\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        cursor.execute(\"\"\"\n            INSERT INTO error_log \n                (report_id, execution_id, error_source, error_type, error_message,\n                 stack_trace, dag_id, task_id)\n            VALUES \n                (:report_id, :execution_id, :error_source, :error_type, :error_message,\n                 :stack_trace, :dag_id, :task_id)\n        \"\"\", report_id=report_id, execution_id=execution_id, error_source=error_source,\n             error_type=error_type, error_message=error_message, stack_trace=stack_trace,\n             dag_id=dag_id, task_id=task_id)\n        \n        connection.commit()\n        cursor.close()\n        \n        logger.info(f\"Logged error for report {report_id}: {error_message}\")\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error logging error (meta!): {error}\")\n        if connection:\n            connection.rollback()\n    finally:\n        if connection:\n            connection.close()\n\n\ndef get_system_config(config_key: str, default_value: str = None) -> str:\n    \"\"\"\n    Get a system configuration value\n    \n    Args:\n        config_key: Configuration key to retrieve\n        default_value: Default value if not found\n        \n    Returns:\n        Configuration value or default\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        cursor.execute(\"\"\"\n            SELECT config_value\n            FROM system_config\n            WHERE config_key = :config_key\n        \"\"\", config_key=config_key)\n        \n        row = cursor.fetchone()\n        cursor.close()\n        \n        if row:\n            return row[0]\n        else:\n            logger.warning(f\"Config key {config_key} not found, using default: {default_value}\")\n            return default_value\n            \n    except oracledb.Error as error:\n        logger.error(f\"Database error retrieving config: {error}\")\n        return default_value\n    finally:\n        if connection:\n            connection.close()\n\n\ndef set_system_config(config_key: str, config_value: str, config_type: str = 'STRING',\n                     description: str = None, modified_by: str = 'SYSTEM'):\n    \"\"\"\n    Set a system configuration value\n    \n    Args:\n        config_key: Configuration key\n        config_value: Configuration value\n        config_type: Type of configuration ('STRING', 'NUMBER', 'BOOLEAN', 'JSON')\n        description: Description of the configuration\n        modified_by: User making the modification\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        cursor.execute(\"\"\"\n            MERGE INTO system_config sc\n            USING DUAL ON (sc.config_key = :config_key)\n            WHEN MATCHED THEN\n                UPDATE SET config_value = :config_value,\n                          modified_date = SYSTIMESTAMP,\n                          modified_by = :modified_by\n            WHEN NOT MATCHED THEN\n                INSERT (config_key, config_value, config_type, description, modified_by)\n                VALUES (:config_key, :config_value, :config_type, :description, :modified_by)\n        \"\"\", config_key=config_key, config_value=config_value, config_type=config_type,\n             description=description, modified_by=modified_by)\n        \n        connection.commit()\n        cursor.close()\n        \n        logger.info(f\"Set system config {config_key} = {config_value}\")\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error setting config: {error}\")\n        if connection:\n            connection.rollback()\n    finally:\n        if connection:\n            connection.close()\n\n\ndef get_execution_history(report_id: str = None, days: int = 7) -> List[Dict[str, Any]]:\n    \"\"\"\n    Get execution history for a report or all reports\n    \n    Args:\n        report_id: Optional report ID to filter by\n        days: Number of days to look back\n        \n    Returns:\n        List of execution history records\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        if report_id:\n            cursor.execute(\"\"\"\n                SELECT execution_id, report_id, execution_date, status, \n                       records_processed, error_message, pdf_file_path\n                FROM report_execution_history\n                WHERE report_id = :report_id \n                  AND execution_date >= SYSTIMESTAMP - INTERVAL :days DAY\n                ORDER BY execution_date DESC\n            \"\"\", report_id=report_id, days=str(days))\n        else:\n            cursor.execute(\"\"\"\n                SELECT execution_id, report_id, execution_date, status, \n                       records_processed, error_message, pdf_file_path\n                FROM report_execution_history\n                WHERE execution_date >= SYSTIMESTAMP - INTERVAL :days DAY\n                ORDER BY execution_date DESC\n            \"\"\", days=str(days))\n        \n        results = []\n        for row in cursor.fetchall():\n            results.append({\n                \"execution_id\": row[0],\n                \"report_id\": row[1],\n                \"execution_date\": row[2].isoformat() if row[2] else None,\n                \"status\": row[3],\n                \"records_processed\": row[4],\n                \"error_message\": row[5],\n                \"pdf_file_path\": row[6]\n            })\n        \n        cursor.close()\n        return results\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error retrieving execution history: {error}\")\n        return []\n    finally:\n        if connection:\n            connection.close()","size_bytes":19000},"dags/order_search_report_dag.py":{"content":"# order_report_dag.py\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.email import EmailOperator\nfrom airflow.models import Variable\nimport requests\nimport json\nimport pandas as pd\nimport logging\nimport os\nimport sys\nsys.path.append(\"/opt/airflow\")\nfrom utils.report_utils import query_order_api, generate_pdf_report\nfrom reportlab.lib import colors\nfrom reportlab.lib.pagesizes import letter, landscape\nfrom reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\nfrom reportlab.lib.styles import getSampleStyleSheet\nfrom airflow.utils.dates import days_ago\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"order_report_service\")\n\n# Define default arguments for the DAG\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 3,\n    'retry_delay': timedelta(minutes=5),\n}\n\n# Function to query the order search API\ndef query_order_api(**kwargs):\n    \"\"\"\n    Query the order search API for a specific date range\n    \"\"\"\n    # Get execution date from context\n    execution_date = kwargs['execution_date']\n    \n    # Get API configuration from Airflow Variables\n    api_base_url = Variable.get(\"order_api_base_url\")\n    search_endpoint = f\"{api_base_url}/order/search\"\n    \n    # Calculate date range (yesterday to execution date)\n    to_date = execution_date.strftime(\"%d %b %Y\")\n    from_date = (execution_date - timedelta(days=1)).strftime(\"%d %b %Y\")\n    \n    logger.info(f\"Searching orders from {from_date} to {to_date}\")\n    \n    # Build API search payload\n    payload = {\n        \"ViewName\": \"orderdetails\",\n        \"Filters\": [\n            {\n                \"ViewName\": \"orderdetails\",\n                \"AttributeId\": \"OrderDate\",\n                \"DataType\": None,\n                \"requiredFilter\": False,\n                \"FilterValues\": [\n                    {\n                        \"filter\": {\n                            \"date\": {\n                                \"from\": from_date,\n                                \"to\": to_date\n                            },\n                            \"time\": {\n                                \"from\": \"00:00\",\n                                \"to\": \"23:59\",\n                                \"start\": 0,\n                                \"end\": 288\n                            },\n                            \"quickSelect\": \"CUSTOM\"\n                        }\n                    }\n                ],\n                \"negativeFilter\": False\n            }\n        ],\n        \"RequestAttributeIds\": [],\n        \"SearchOptions\": [],\n        \"SearchChains\": [],\n        \"FilterExpression\": None,\n        \"Page\": 0,\n        \"TotalCount\": -1,\n        \"SortOrder\": \"desc\",\n        \"SortIndicator\": \"chevron-up\",\n        \"TimeZone\": \"America/Chicago\",\n        \"IsCommonUI\": False,\n        \"ComponentShortName\": None,\n        \"EnableMaxCountLimit\": True,\n        \"MaxCountLimit\": 1000,\n        \"ComponentName\": \"com-manh-cp-xint\",\n        \"Size\": 100,\n        \"Sort\": \"OrderDate\"\n    }\n\n    # Query parameter - can be configured in Airflow Variables\n    order_type = Variable.get(\"order_type\", \"StandardOrder\")\n    \n    # Add order type filter if specified\n    if order_type:\n        payload[\"Filters\"].append({\n            \"ViewName\": \"orderdetails\",\n            \"AttributeId\": \"TextSearch\",\n            \"DataType\": \"text\",\n            \"requiredFilter\": False,\n            \"FilterValues\": [\n                f\"\\\"{order_type}\\\"\"\n            ],\n            \"negativeFilter\": False\n        })\n    \n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {Variable.get('api_token', '')}\"\n    }\n    \n    all_results = []\n    page = 0\n    \n    try:\n        while True:\n            payload[\"Page\"] = page\n            logger.info(f\"Searching page {page}...\")\n            \n            response = requests.post(\n                search_endpoint, \n                json=payload,\n                headers=headers\n            )\n            \n            if response.status_code != 200:\n                logger.error(f\"Error in API call: {response.status_code} - {response.text}\")\n                raise Exception(f\"API returned error: {response.status_code}\")\n            \n            result_data = response.json()\n            \n            # Check if we have results\n            if not result_data.get(\"data\") or len(result_data[\"data\"]) == 0:\n                logger.info(f\"No more results found after page {page}\")\n                break\n            \n            all_results.extend(result_data[\"data\"])\n            logger.info(f\"Retrieved {len(result_data['data'])} orders from page {page}\")\n            \n            # Check if we've reached the end\n            if len(all_results) >= result_data.get(\"totalCount\", 0) or len(result_data[\"data\"]) < payload[\"Size\"]:\n                break\n            \n            page += 1\n    \n    except Exception as e:\n        logger.error(f\"Error during API search: {str(e)}\")\n        raise\n    \n    logger.info(f\"Total orders retrieved: {len(all_results)}\")\n    \n    # Create a temporary file to store the results\n    result_file = f\"/tmp/order_results_{execution_date.strftime('%Y%m%d')}.json\"\n    with open(result_file, 'w') as f:\n        json.dump(all_results, f)\n    \n    # Return the path to the result file for the next task\n    return result_file\n\n# Function to generate a PDF report from the API results\ndef generate_pdf_report(**kwargs):\n    \"\"\"\n    Generate a PDF report from the API results\n    \"\"\"\n    # Get the task instance\n    ti = kwargs['ti']\n    \n    # Get the result file path from the previous task\n    result_file = ti.xcom_pull(task_ids='query_order_api')\n    execution_date = kwargs['execution_date']\n    \n    logger.info(f\"Generating PDF report from {result_file}\")\n    \n    # Load the results\n    with open(result_file, 'r') as f:\n        results = json.load(f)\n    \n    if not results:\n        logger.warning(\"No results found for report generation\")\n        # Create an empty PDF with a message\n        pdf_file = f\"/tmp/order_report_{execution_date.strftime('%Y%m%d')}.pdf\"\n        doc = SimpleDocTemplate(pdf_file, pagesize=letter)\n        styles = getSampleStyleSheet()\n        elements = []\n        elements.append(Paragraph(f\"Order Report - {execution_date.strftime('%Y-%m-%d')}\", styles['Title']))\n        elements.append(Spacer(1, 12))\n        elements.append(Paragraph(\"No orders found for the specified period.\", styles['Normal']))\n        doc.build(elements)\n        return pdf_file\n    \n    # Extract relevant fields for the report\n    # Adjust these fields based on your API response structure\n    report_data = []\n    \n    # Add header row\n    headers = [\"Order ID\", \"Order Date\", \"Customer\", \"Status\", \"Total Items\", \"Total Value\"]\n    report_data.append(headers)\n    \n    # Add data rows\n    for order in results:\n        try:\n            row = [\n                order.get(\"OrderId\", \"N/A\"),\n                order.get(\"OrderDate\", \"N/A\"),\n                order.get(\"CustomerName\", \"N/A\"),\n                order.get(\"Status\", \"N/A\"),\n                str(order.get(\"TotalItems\", 0)),\n                f\"${order.get('TotalValue', 0):.2f}\"\n            ]\n            report_data.append(row)\n        except KeyError as e:\n            logger.error(f\"Error extracting order data: {str(e)}\")\n            continue\n    \n    # Create a DataFrame for summary statistics\n    df = pd.DataFrame(report_data[1:], columns=report_data[0])\n    df['Total Value'] = df['Total Value'].str.replace('$', '').astype(float)\n    df['Total Items'] = df['Total Items'].astype(int)\n    \n    # Calculate summary statistics\n    total_orders = len(df)\n    total_value = df['Total Value'].sum()\n    total_items = df['Total Items'].sum()\n    average_value = df['Total Value'].mean() if total_orders > 0 else 0\n    \n    # Generate the PDF\n    pdf_file = f\"/tmp/order_report_{execution_date.strftime('%Y%m%d')}.pdf\"\n    doc = SimpleDocTemplate(pdf_file, pagesize=landscape(letter))\n    \n    styles = getSampleStyleSheet()\n    elements = []\n    \n    # Add title\n    title = f\"Order Report - {execution_date.strftime('%Y-%m-%d')}\"\n    elements.append(Paragraph(title, styles['Title']))\n    elements.append(Spacer(1, 12))\n    \n    # Add summary section\n    elements.append(Paragraph(\"Summary\", styles['Heading2']))\n    summary_data = [\n        [\"Total Orders\", str(total_orders)],\n        [\"Total Items\", str(total_items)],\n        [\"Total Value\", f\"${total_value:.2f}\"],\n        [\"Average Order Value\", f\"${average_value:.2f}\"]\n    ]\n    \n    summary_table = Table(summary_data, colWidths=[200, 150])\n    summary_table.setStyle(TableStyle([\n        ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),\n        ('TEXTCOLOR', (0, 0), (0, -1), colors.black),\n        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),\n        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),\n        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n    ]))\n    elements.append(summary_table)\n    elements.append(Spacer(1, 24))\n    \n    # Add main table\n    elements.append(Paragraph(\"Order Details\", styles['Heading2']))\n    \n    # Create the table\n    table = Table(report_data)\n    \n    # Style the table\n    table_style = TableStyle([\n        ('BACKGROUND', (0, 0), (-1, 0), colors.blue),\n        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n        ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n        ('FONTSIZE', (0, 0), (-1, 0), 12),\n        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n        ('ALIGN', (0, 1), (-1, -1), 'LEFT'),\n        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n        ('FONTSIZE', (0, 1), (-1, -1), 10),\n        ('BOTTOMPADDING', (0, 1), (-1, -1), 8),\n        ('GRID', (0, 0), (-1, -1), 1, colors.black),\n        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n    ])\n    \n    # Add a zebra striping pattern\n    for i in range(1, len(report_data)):\n        if i % 2 == 0:\n            table_style.add('BACKGROUND', (0, i), (-1, i), colors.lightgrey)\n    \n    table.setStyle(table_style)\n    elements.append(table)\n    \n    # Build the PDF\n    doc.build(elements)\n    \n    logger.info(f\"PDF report generated: {pdf_file}\")\n    return pdf_file\n\n# Create the DAG\ndag = DAG(\n    'order_search_report',\n    default_args=default_args,\n    description='Search for orders, generate a PDF report, and email it',\n    schedule_interval='0 8 * * *',  # Run daily at 8:00 AM\n    start_date=days_ago(1),\n    catchup=False,\n    tags=['order', 'report'],\n)\n\n# Task 1: Query the order API\ntask_query_api = PythonOperator(\n    task_id='query_order_api',\n    python_callable=query_order_api,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 2: Generate the PDF report\ntask_generate_pdf = PythonOperator(\n    task_id='generate_pdf_report',\n    python_callable=generate_pdf_report,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 3: Email the PDF report\ntask_email_report = EmailOperator(\n    task_id='email_report',\n    to=\"{{ var.value.report_recipients }}\",\n    subject=\"Daily Order Report - {{ ds }}\",\n    html_content=\"\"\"\n        <p>Hello,</p>\n        <p>Please find attached the daily order report for {{ ds }}.</p>\n        <p>This report contains a summary of all orders processed in the last 24 hours.</p>\n        <p>Best regards,<br/>Automated Reporting System</p>\n    \"\"\",\n    files=[\"{{ ti.xcom_pull(task_ids='generate_pdf_report') }}\"],\n    dag=dag,\n)\n\n# Define task dependencies\ntask_query_api >> task_generate_pdf >> task_email_report","size_bytes":11711},"dags/mongodb_monitoring_dag.py":{"content":"# dags/mongodb_reporting_dag.py\nfrom datetime import datetime, timedelta\nimport logging\nimport json\nimport os\nimport sys\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.empty import EmptyOperator\nfrom airflow.models import Variable\nfrom airflow.utils.dates import days_ago\n\n# Add utils directory to path for local imports\nsys.path.append(os.path.join(os.path.dirname(__file__), \"..\"))\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"mongodb_reporting\")\n\n# Define default arguments for the DAG\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\ndef check_mongodb_connection(**kwargs):\n    \"\"\"\n    Test the connection to MongoDB\n    \"\"\"\n    try:\n        from utils.mongo_utils import get_mongo_client\n        \n        # Attempt to connect to MongoDB\n        client = get_mongo_client()\n        \n        # Get database name\n        db_name = os.environ.get(\n            \"MONGODB_DATABASE\", \n            Variable.get(\"mongodb_database\", \"order_reports\")\n        )\n        \n        # Get database stats\n        db_stats = client[db_name].command(\"dbstats\")\n        \n        # Log some basic info\n        logger.info(f\"Successfully connected to MongoDB\")\n        logger.info(f\"Database: {db_name}\")\n        logger.info(f\"Collections: {client[db_name].list_collection_names()}\")\n        logger.info(f\"Database size: {db_stats.get('dataSize', 0) / (1024*1024):.2f} MB\")\n        \n        return {\n            \"status\": \"success\",\n            \"collections\": client[db_name].list_collection_names(),\n            \"db_size_mb\": db_stats.get('dataSize', 0) / (1024*1024)\n        }\n    except Exception as e:\n        logger.error(f\"Error connecting to MongoDB: {str(e)}\")\n        return {\n            \"status\": \"error\",\n            \"error\": str(e)\n        }\n\ndef list_recent_responses(**kwargs):\n    \"\"\"\n    List recent API responses stored in MongoDB\n    \"\"\"\n    try:\n        from utils.mongo_utils import get_mongo_client\n        \n        # Get MongoDB client\n        client = get_mongo_client()\n        \n        # Get database and collection names\n        db_name = os.environ.get(\n            \"MONGODB_DATABASE\", \n            Variable.get(\"mongodb_database\", \"order_reports\")\n        )\n        collection_name = os.environ.get(\n            \"MONGODB_COLLECTION\", \n            Variable.get(\"mongodb_collection\", \"api_responses\")\n        )\n        \n        # Access the database and collection\n        db = client[db_name]\n        collection = db[collection_name]\n        \n        # Find recent documents\n        cursor = collection.find().sort(\"timestamp\", -1).limit(10)\n        \n        # Convert results to a list of dictionaries\n        results = []\n        for doc in cursor:\n            # Convert ObjectId to string\n            doc['_id'] = str(doc['_id'])\n            # Convert datetime to string\n            if 'timestamp' in doc:\n                doc['timestamp'] = doc['timestamp'].isoformat()\n            \n            # Extract summary data\n            result = {\n                \"_id\": doc['_id'],\n                \"timestamp\": doc['timestamp'],\n                \"report_id\": doc.get('report_id', 'unknown'),\n                \"record_count\": doc.get('record_count', 0)\n            }\n            \n            # Include query parameters summary\n            if 'query_parameters' in doc:\n                params = doc['query_parameters']\n                result['query'] = {\n                    \"from_date\": params.get('from_date', ''),\n                    \"to_date\": params.get('to_date', '')\n                }\n            \n            results.append(result)\n        \n        # Log summary\n        logger.info(f\"Found {len(results)} recent API responses\")\n        \n        # Save results to a file\n        output_file = f\"/tmp/recent_responses_{kwargs['execution_date'].strftime('%Y%m%d')}.json\"\n        with open(output_file, 'w') as f:\n            json.dump(results, f, indent=2)\n        \n        return results\n    \n    except Exception as e:\n        logger.error(f\"Error listing recent responses: {str(e)}\")\n        return []\n\n# Create the DAG\ndag = DAG(\n    'mongodb_reporting',\n    default_args=default_args,\n    description='MongoDB connection and reporting',\n    schedule_interval='@daily',\n    start_date=days_ago(1),\n    catchup=False,\n    tags=['mongodb', 'reporting'],\n)\n\n# Task 1: Check MongoDB connection\ntask_check_connection = PythonOperator(\n    task_id='check_mongodb_connection',\n    python_callable=check_mongodb_connection,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 2: List recent responses\ntask_list_responses = PythonOperator(\n    task_id='list_recent_responses',\n    python_callable=list_recent_responses,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 3: End task\ntask_end = EmptyOperator(\n    task_id='end',\n    dag=dag,\n)\n\n# Define task dependencies\ntask_check_connection >> task_list_responses >> task_end","size_bytes":5138},"dags/custom_report_configuration_dag.py":{"content":"# custom_report_config_dag.py\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.providers.http.operators.http import SimpleHttpOperator\nfrom airflow.utils.dates import days_ago\nfrom airflow.models import Variable\nimport json\nimport logging\nimport sys\nsys.path.append('/opt/airflow')\nfrom utils.report_utils import query_order_api, generate_pdf_report\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"report_config_service\")\n\n# Define default arguments for the DAG\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\n# Function to update report configurations\ndef update_report_configs(**kwargs):\n    \"\"\"\n    Update report configurations from a configuration file or API\n    \"\"\"\n    try:\n        # In a real scenario, this might come from a database or external API\n        report_configs = [\n            {\n                \"report_id\": \"daily_order_summary\",\n                \"name\": \"Daily Order Summary\",\n                \"description\": \"Summary of all orders processed in the last 24 hours\",\n                \"schedule\": \"0 8 * * *\",\n                \"query_parameters\": {\n                    \"order_type\": \"StandardOrder\",\n                    \"view_name\": \"orderdetails\",\n                    \"sort_field\": \"OrderDate\"\n                },\n                \"email\": {\n                    \"recipients\": [\"team@example.com\", \"managers@example.com\"],\n                    \"subject\": \"Daily Order Summary - {date}\",\n                    \"body\": \"Please find attached the daily order summary report.\"\n                },\n                \"report_fields\": [\n                    \"OrderId\", \"OrderDate\", \"CustomerName\", \"Status\", \"TotalItems\", \"TotalValue\"\n                ],\n                \"summary_fields\": [\n                    {\"field\": \"TotalValue\", \"operation\": \"sum\", \"label\": \"Total Revenue\"},\n                    {\"field\": \"TotalItems\", \"operation\": \"sum\", \"label\": \"Total Items\"},\n                    {\"field\": \"OrderId\", \"operation\": \"count\", \"label\": \"Order Count\"}\n                ],\n                \"active\": True\n            },\n            {\n                \"report_id\": \"exception_orders\",\n                \"name\": \"Exception Orders Report\",\n                \"description\": \"Orders with exceptions or errors\",\n                \"schedule\": \"0 9 * * *\",\n                \"query_parameters\": {\n                    \"order_type\": \"ExceptionOrder\",\n                    \"view_name\": \"orderdetails\",\n                    \"sort_field\": \"OrderDate\"\n                },\n                \"email\": {\n                    \"recipients\": [\"exceptions@example.com\", \"support@example.com\"],\n                    \"subject\": \"Exception Orders Report - {date}\",\n                    \"body\": \"Please find attached the exception orders report that requires attention.\"\n                },\n                \"report_fields\": [\n                    \"OrderId\", \"OrderDate\", \"CustomerName\", \"ExceptionCode\", \"ExceptionDesc\", \"PriorityLevel\"\n                ],\n                \"summary_fields\": [\n                    {\"field\": \"ExceptionCode\", \"operation\": \"group\", \"label\": \"Exceptions by Type\"},\n                    {\"field\": \"PriorityLevel\", \"operation\": \"group\", \"label\": \"Exceptions by Priority\"}\n                ],\n                \"active\": True\n            }\n        ]\n        \n        # Store each configuration as a separate variable\n        for config in report_configs:\n            Variable.set(\n                f\"report_config_{config['report_id']}\", \n                json.dumps(config),\n                serialize_json=True\n            )\n            logger.info(f\"Updated configuration for report: {config['report_id']}\")\n        \n        # Store the list of available reports\n        report_ids = [config[\"report_id\"] for config in report_configs if config.get(\"active\", True)]\n        Variable.set(\"active_report_ids\", json.dumps(report_ids), serialize_json=True)\n        \n        return report_ids\n        \n    except Exception as e:\n        logger.error(f\"Error updating report configurations: {str(e)}\")\n        raise\n\n# Function to test API connectivity\ndef test_api_connectivity(**kwargs):\n    \"\"\"\n    Test the connectivity to the order search API\n    \"\"\"\n    api_base_url = Variable.get(\"order_api_base_url\")\n    test_endpoint = f\"{api_base_url}/health\"\n    \n    try:\n        import requests\n        response = requests.get(test_endpoint)\n        \n        if response.status_code == 200:\n            logger.info(\"API connectivity test successful\")\n            return True\n        else:\n            logger.error(f\"API connectivity test failed: {response.status_code} - {response.text}\")\n            return False\n    except Exception as e:\n        logger.error(f\"API connectivity test exception: {str(e)}\")\n        return False\n\n# Create the DAG\ndag = DAG(\n    'report_configuration_manager',\n    default_args=default_args,\n    description='Manage and update report configurations',\n    schedule_interval='@daily',  # Run once per day\n    start_date=days_ago(1),\n    catchup=False,\n    tags=['config', 'report'],\n)\n\n# Task 1: Update report configurations\ntask_update_configs = PythonOperator(\n    task_id='update_report_configs',\n    python_callable=update_report_configs,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 2: Test API connectivity\ntask_test_api = PythonOperator(\n    task_id='test_api_connectivity',\n    python_callable=test_api_connectivity,\n    provide_context=True,\n    dag=dag,\n)\n\n# Define task dependencies\ntask_update_configs >> task_test_api","size_bytes":5773},"dags/dynamic_report_generator_dag.py":{"content":"# improved_dynamic_report_generator_dag.py\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator, BranchPythonOperator\nfrom airflow.operators.email import EmailOperator\nfrom airflow.operators.empty import EmptyOperator as DummyOperator\nfrom airflow.models import Variable\nfrom airflow.utils.task_group import TaskGroup\nfrom airflow.utils.dates import days_ago\nimport json\nimport logging\nimport os\nimport sys\nsys.path.append(\"/opt/airflow\")\nfrom utils.report_utils import query_order_api, generate_pdf_report\n\n\n\n# Add project root to path for local imports\nsys.path.append(os.path.join(os.path.dirname(__file__), \"..\"))\nfrom utils.report_utils import query_order_api, generate_pdf_report\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"dynamic_report_generator\")\n\n# Define default arguments for the DAG\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 3,\n    'retry_delay': timedelta(minutes=5),\n}\n\n# Function to get active report configurations\ndef get_active_reports(**kwargs):\n    \"\"\"\n    Get the list of active report configurations and decide which branches to execute\n    \"\"\"\n    try:\n        active_report_ids = json.loads(Variable.get(\"active_report_ids\", \"[]\"))\n        if not active_report_ids:\n            logger.warning(\"No active reports found\")\n            return ['no_active_reports']\n        \n        logger.info(f\"Found {len(active_report_ids)} active reports: {active_report_ids}\")\n        \n        # Return task IDs corresponding to each report\n        return [f\"process_report_{report_id}\" for report_id in active_report_ids]\n    \n    except Exception as e:\n        logger.error(f\"Error retrieving active reports: {str(e)}\")\n        return ['no_active_reports']\n\n# Function to query the API for a specific report\ndef query_report_data(report_id, **kwargs):\n    \"\"\"\n    Query the API based on report configuration\n    \"\"\"\n    # Get execution date from context\n    execution_date = kwargs['execution_date']\n    \n    # Load report configuration\n    try:\n        report_config = json.loads(Variable.get(f\"report_config_{report_id}\"))\n    except Exception as e:\n        logger.error(f\"Error loading configuration for report {report_id}: {str(e)}\")\n        raise\n    \n    # Calculate date range (yesterday to execution date)\n    to_date = execution_date.strftime(\"%d %b %Y\")\n    from_date = (execution_date - timedelta(days=1)).strftime(\"%d %b %Y\")\n    \n    logger.info(f\"[{report_id}] Searching from {from_date} to {to_date}\")\n    \n    # Query the API using the utility function\n    results = query_order_api(from_date, to_date, report_config)\n    \n    # Create a temporary file to store the results\n    result_file = f\"/tmp/{report_id}_results_{execution_date.strftime('%Y%m%d')}.json\"\n    with open(result_file, 'w') as f:\n        json.dump({\n            \"report_id\": report_id,\n            \"config\": report_config,\n            \"data\": results,\n            \"executed_at\": execution_date.isoformat()\n        }, f)\n    \n    # Return the path to the result file\n    return result_file\n\n# Function to generate PDF for a specific report\ndef generate_report_pdf(report_id, **kwargs):\n    \"\"\"\n    Generate a PDF report based on the query results and report configuration\n    \"\"\"\n    # Get the task instance\n    ti = kwargs['ti']\n    execution_date = kwargs['execution_date']\n    \n    # Get the result file path from the previous task\n    result_file = ti.xcom_pull(task_ids=f\"query_data_{report_id}\")\n    \n    logger.info(f\"[{report_id}] Generating PDF report from {result_file}\")\n    \n    # Load the results and configuration\n    with open(result_file, 'r') as f:\n        result_data = json.load(f)\n    \n    report_config = result_data[\"config\"]\n    results = result_data[\"data\"]\n    \n    # Generate the PDF using the utility function\n    pdf_file = generate_pdf_report(\n        report_title=report_config['name'],\n        results=results,\n        report_config=report_config,\n        execution_date=execution_date\n    )\n    \n    return pdf_file\n\n# Function to email the report\ndef prepare_email(report_id, **kwargs):\n    \"\"\"\n    Prepare email parameters for the generated PDF report\n    \"\"\"\n    # Get the task instance\n    ti = kwargs['ti']\n    execution_date = kwargs['execution_date']\n    \n    # Get the PDF file path from the previous task\n    pdf_file = ti.xcom_pull(task_ids=f\"generate_pdf_{report_id}\")\n    \n    # Load report configuration to get email settings\n    try:\n        report_config = json.loads(Variable.get(f\"report_config_{report_id}\"))\n    except Exception as e:\n        logger.error(f\"Error loading configuration for report {report_id}: {str(e)}\")\n        raise\n    \n    # Get email configuration\n    email_config = report_config.get(\"email\", {})\n    recipients = email_config.get(\"recipients\", [])\n    subject = email_config.get(\"subject\", \"Report\").format(date=execution_date.strftime('%Y-%m-%d'))\n    body = email_config.get(\"body\", \"Please find attached the requested report.\")\n    \n    if not recipients:\n        logger.warning(f\"[{report_id}] No recipients configured for report, using default\")\n        recipients = Variable.get(\"default_report_recipients\", \"admin@example.com\").split(',')\n    \n    logger.info(f\"[{report_id}] Sending report to {len(recipients)} recipients: {recipients}\")\n    \n    # Return the email parameters\n    return {\n        \"file_path\": pdf_file,\n        \"recipients\": recipients,\n        \"subject\": subject,\n        \"body\": body\n    }\n\n# Create the DAG\ndag = DAG(\n    'dynamic_report_generator',\n    default_args=default_args,\n    description='Dynamically generate and email reports based on configurations',\n    schedule_interval='0 7 * * *',  # Run daily at 7:00 AM\n    start_date=days_ago(1),\n    catchup=False,\n    tags=['report', 'dynamic'],\n)\n\n# Task to determine which reports to run\nbranching = BranchPythonOperator(\n    task_id='get_active_reports',\n    python_callable=get_active_reports,\n    provide_context=True,\n    dag=dag,\n)\n\n# End task\nend = DummyOperator(\n    task_id='end',\n    trigger_rule='none_failed_min_one_success',\n    dag=dag,\n)\n\n# No active reports task\nno_active_reports = DummyOperator(\n    task_id='no_active_reports',\n    dag=dag,\n)\n\n# Connect no_active_reports to branching and end\nbranching >> no_active_reports >> end\n\n# Get the active report IDs at DAG definition time\n# This is only used for setting up the task structure\n# The actual active reports will be determined at runtime\ntry:\n    active_report_ids = json.loads(Variable.get(\"active_report_ids\", \"[]\"))\nexcept:\n    active_report_ids = []\n\n# Create task groups for each report\nfor report_id in active_report_ids:\n    with TaskGroup(group_id=f\"process_report_{report_id}\", dag=dag) as report_group:\n        # Task to query the API\n        query_task = PythonOperator(\n            task_id=f\"query_data_{report_id}\",\n            python_callable=query_report_data,\n            op_kwargs={\"report_id\": report_id},\n            provide_context=True,\n        )\n        \n        # Task to generate the PDF\n        pdf_task = PythonOperator(\n            task_id=f\"generate_pdf_{report_id}\",\n            python_callable=generate_report_pdf,\n            op_kwargs={\"report_id\": report_id},\n            provide_context=True,\n        )\n        \n        # Task to prepare email\n        email_prep_task = PythonOperator(\n            task_id=f\"prepare_email_{report_id}\",\n            python_callable=prepare_email,\n            op_kwargs={\"report_id\": report_id},\n            provide_context=True,\n        )\n        \n        # Task to send email with enhanced HTML template\n        email_task = EmailOperator(\n            task_id=f\"send_email_{report_id}\",\n            to=\"{{ ti.xcom_pull(task_ids='prepare_email_\" + report_id + \"')['recipients'] }}\",\n            subject=\"{{ ti.xcom_pull(task_ids='prepare_email_\" + report_id + \"')['subject'] }}\",\n            html_content=\"\"\"\n                <html>\n                <head>\n                    <style>\n                        body { font-family: Arial, sans-serif; margin: 0; padding: 0; color: #333; }\n                        .header { background-color: #4285f4; color: white; padding: 20px; }\n                        .content { padding: 20px; }\n                        .footer { font-size: 12px; color: #999; padding: 20px; border-top: 1px solid #eee; }\n                        .note { background-color: #f8f9fa; border-left: 4px solid #4285f4; padding: 15px; margin: 15px 0; }\n                    </style>\n                </head>\n                <body>\n                    <div class=\"header\">\n                        <h2>{{ ti.xcom_pull(task_ids='prepare_email_\"\"\" + report_id + \"\"\"')['subject'] }}</h2>\n                    </div>\n                    <div class=\"content\">\n                        <p>{{ ti.xcom_pull(task_ids='prepare_email_\"\"\" + report_id + \"\"\"')['body'] }}</p>\n                        <div class=\"note\">\n                            <p><strong>Report Date Range:</strong> {{ (execution_date - macros.timedelta(days=1)).strftime('%Y-%m-%d') }} to {{ execution_date.strftime('%Y-%m-%d') }}</p>\n                            <p><strong>Generated On:</strong> {{ execution_date.strftime('%Y-%m-%d %H:%M:%S') }}</p>\n                        </div>\n                    </div>\n                    <div class=\"footer\">\n                        <p>This is an automated report. Please do not reply to this email.</p>\n                        <p>If you have any questions about this report, please contact the operations team.</p>\n                    </div>\n                </body>\n                </html>\n            \"\"\",\n            files=[\"{{ ti.xcom_pull(task_ids='prepare_email_\" + report_id + \"')['file_path'] }}\"],\n        )\n        \n        # Set up dependencies within the group\n        query_task >> pdf_task >> email_prep_task >> email_task\n    \n    # Connect group to branching and end tasks\n    branching >> report_group >> end","size_bytes":10109},"utils/mongo_utils.py":{"content":"# utils/mongo_utils.py\nimport json\nimport logging\nimport os\nfrom datetime import datetime\nfrom pymongo import MongoClient\nfrom airflow.models import Variable\n\nlogger = logging.getLogger(\"mongo_utils\")\n\ndef get_mongo_client():\n    \"\"\"\n    Get a MongoDB client using connection details from environment variables or Airflow variables\n    \n    Returns:\n        MongoClient: A configured MongoDB client\n    \"\"\"\n    # Try to get connection string from environment or Airflow variables\n    connection_string = os.environ.get(\n        \"MONGODB_CONNECTION_STRING\", \n        Variable.get(\"mongodb_connection_string\", \"mongodb://mongodb:27017/\")\n    )\n    \n    try:\n        client = MongoClient(connection_string, serverSelectionTimeoutMS=5000)\n        # Test connection\n        client.server_info()\n        logger.info(\"Successfully connected to MongoDB\")\n        return client\n    except Exception as e:\n        logger.error(f\"Error connecting to MongoDB: {str(e)}\")\n        # Still return the client, so calling code can handle errors appropriately\n        return client\n\ndef log_api_response(response_data, report_id=None, query_params=None):\n    \"\"\"\n    Log an API response to MongoDB\n    \n    Args:\n        response_data (dict or list): The API response data to log\n        report_id (str, optional): The ID of the report being generated\n        query_params (dict, optional): The query parameters used in the API request\n        \n    Returns:\n        str: The ID of the inserted document in MongoDB or None if failed\n    \"\"\"\n    try:\n        # Get MongoDB connection\n        client = get_mongo_client()\n        \n        # Get database and collection names from environment or Airflow variables\n        db_name = os.environ.get(\n            \"MONGODB_DATABASE\", \n            Variable.get(\"mongodb_database\", \"order_reports\")\n        )\n        collection_name = os.environ.get(\n            \"MONGODB_COLLECTION\", \n            Variable.get(\"mongodb_collection\", \"api_responses\")\n        )\n        \n        # Access the database and collection\n        db = client[db_name]\n        collection = db[collection_name]\n        \n        # Prepare the document to insert\n        document = {\n            \"timestamp\": datetime.now(),\n            \"report_id\": report_id,\n            \"query_parameters\": query_params,\n            \"response_data\": response_data,\n            \"record_count\": len(response_data) if isinstance(response_data, list) else 1\n        }\n        \n        # Insert the document\n        result = collection.insert_one(document)\n        logger.info(f\"Logged API response to MongoDB with ID: {result.inserted_id}\")\n        \n        return str(result.inserted_id)\n        \n    except Exception as e:\n        logger.error(f\"Error logging API response to MongoDB: {str(e)}\")\n        # Don't raise exception to avoid breaking the main workflow\n        return None","size_bytes":2859},"USER_AUTH_SETUP_GUIDE.md":{"content":"# User Authentication Tables Setup Guide\n\n## Issue Identified\n\nThe original database initialization script (`init-scripts/01_create_schema.sql`) was **missing all user authentication tables**. This is why user tables were not being created on startup.\n\n### What Was Missing:\n- `users` table - stores user accounts with hashed passwords\n- `roles` table - defines system roles (ADMIN, REPORT_MANAGER, etc.)\n- `user_roles` table - maps users to roles (many-to-many)\n- `report_permissions` table - controls what roles can do with reports\n- `user_activity_log` table - tracks all user actions for security auditing\n\n## Solution\n\nI've created three new files to fix this:\n\n1. **02_create_user_tables.sql** - SQL script to create all missing user tables\n2. **user_management.py** - Python module with secure password hashing and user management\n3. **create_admin_user.py** - CLI tool to create your first admin user\n\n## Setup Instructions\n\n### Step 1: Update Docker Compose\n\nFirst, ensure bcrypt is installed in your Airflow containers. Update the `docker-compose.yaml` to include bcrypt:\n\n```yaml\n# In the airflow-init, airflow-webserver, and airflow-scheduler services:\ncommand: >\n  bash -c \"\n    pip install pymongo pandas matplotlib reportlab requests cx_Oracle bcrypt\n    pip install 'apache-airflow-providers-openlineage>=1.8.0' --no-deps\n    # ... rest of commands\n  \"\n```\n\n### Step 2: Run the User Tables SQL Script\n\nThere are two ways to run the SQL script:\n\n#### Option A: Add to init-scripts directory (Recommended for new deployments)\n\n```bash\n# Copy the SQL script to your init-scripts directory\ncp 02_create_user_tables.sql init-scripts/\n\n# Restart the Oracle container to run the script\ndocker-compose restart oracle-db\n```\n\n#### Option B: Run manually via DBeaver (For existing deployments)\n\n1. Open DBeaver\n2. Connect to your Oracle database (localhost:1521/XEPDB1)\n3. Use credentials: report_user / report_password\n4. Open and execute `02_create_user_tables.sql`\n5. Verify tables were created:\n```sql\nSELECT table_name FROM user_tables \nWHERE table_name IN ('USERS', 'ROLES', 'USER_ROLES', 'REPORT_PERMISSIONS', 'USER_ACTIVITY_LOG');\n```\n\n### Step 3: Install the User Management Module\n\n```bash\n# Copy the user management module to your utils directory\ncp user_management.py utils/\n\n# Make sure it's accessible to Airflow\n# The docker-compose.yaml already mounts ./utils to /opt/airflow/utils\n```\n\n### Step 4: Create Your First Admin User\n\n```bash\n# Make the script executable\nchmod +x create_admin_user.py\n\n# Run the script inside the Airflow container\ndocker exec -it airflow-webserver python /opt/airflow/create_admin_user.py\n\n# Follow the interactive prompts\n```\n\nOr run it directly on your host if you have Oracle client installed:\n\n```bash\npython create_admin_user.py\n```\n\n## Using the User Management Functions\n\n### Example: Create a New User Programmatically\n\n```python\nfrom utils.user_management import create_user\n\n# Create a new user\nuser_id = create_user(\n    username='john_doe',\n    email='john@example.com',\n    password='SecurePass123!',\n    first_name='John',\n    last_name='Doe',\n    roles=['REPORT_VIEWER'],\n    created_by='admin'\n)\n\nif user_id:\n    print(f\"User created with ID: {user_id}\")\n```\n\n### Example: Authenticate a User\n\n```python\nfrom utils.user_management import authenticate_user\n\n# Authenticate user\nuser_info = authenticate_user(\n    username='john_doe',\n    password='SecurePass123!',\n    ip_address='192.168.1.100',\n    user_agent='Mozilla/5.0...'\n)\n\nif user_info:\n    print(f\"Welcome {user_info['first_name']}!\")\n    print(f\"Your roles: {[r['role_name'] for r in user_info['roles']]}\")\nelse:\n    print(\"Authentication failed\")\n```\n\n### Example: Change Password\n\n```python\nfrom utils.user_management import change_password\n\nsuccess = change_password(\n    user_id=123,\n    old_password='SecurePass123!',\n    new_password='NewSecurePass456!'\n)\n```\n\n### Example: Reset Password (Admin Function)\n\n```python\nfrom utils.user_management import reset_password\n\nsuccess = reset_password(\n    user_id=123,\n    new_password='TempPassword123!',\n    reset_by='admin'\n)\n# User will be forced to change password on next login\n```\n\n## Password Requirements\n\nThe system enforces strong password requirements:\n- Minimum 8 characters\n- At least one uppercase letter\n- At least one lowercase letter  \n- At least one digit\n- At least one special character (!@#$%^&*()_+-=[]{}etc.)\n\n## Default Roles\n\nThe system comes with four pre-configured roles:\n\n1. **ADMIN** - Full system access\n   - Can view, execute, modify, and delete all reports\n   - Can manage users and roles\n\n2. **REPORT_MANAGER** - Report management\n   - Can view, execute, and modify reports\n   - Cannot delete reports\n\n3. **REPORT_VIEWER** - View and execute only\n   - Can view and execute reports\n   - Cannot modify or delete reports\n\n4. **REPORT_EXECUTOR** - Execute only\n   - Can view and execute reports\n   - Cannot modify or delete reports\n\n## Security Features\n\n### Password Hashing\n- Uses bcrypt with 12 rounds (industry standard)\n- Passwords are never stored in plain text\n- Each password gets a unique salt\n\n### Account Lockout\n- Account locks after 5 failed login attempts\n- Must be manually unlocked by admin\n\n### Activity Logging\n- All authentication attempts are logged\n- All password changes are tracked\n- All role assignments are recorded\n- Includes IP address and user agent for security audits\n\n### Password Expiry\n- Administrators can force password change on next login\n- Useful for password resets and new user onboarding\n\n## Troubleshooting\n\n### \"Module bcrypt not found\"\n```bash\n# Install bcrypt in the Airflow container\ndocker exec -it airflow-webserver pip install bcrypt\ndocker exec -it airflow-scheduler pip install bcrypt\n```\n\n### \"ORA-00942: table or view does not exist\"\nThe user tables SQL script hasn't been run yet. Follow Step 2 above.\n\n### \"User already exists\"\nThis is normal if you're trying to create a user that already exists. Use a different username.\n\n### \"Password does not meet requirements\"\nCheck the password requirements section above. The password must meet all criteria.\n\n## Integration with Airflow DAGs\n\nYou can integrate user authentication into your DAGs for audit trails:\n\n```python\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom utils.user_management import log_user_activity\n\ndef run_report(**kwargs):\n    user_id = kwargs['dag_run'].conf.get('user_id')\n    \n    # Log the report execution\n    log_user_activity(\n        user_id=user_id,\n        activity_type='REPORT_EXECUTED',\n        activity_description=f'Executed report {kwargs[\"dag\"].dag_id}',\n        success=True\n    )\n    \n    # ... rest of report logic\n\ndag = DAG('secure_report', ...)\n\ntask = PythonOperator(\n    task_id='run_report',\n    python_callable=run_report,\n    provide_context=True,\n    dag=dag\n)\n```\n\n## Next Steps\n\n1. ✓ Create the user tables (Step 2)\n2. ✓ Create your first admin user (Step 4)\n3. Create additional users as needed\n4. Integrate authentication into your DAGs\n5. Set up role-based permissions for reports\n6. Review activity logs regularly for security\n\n## Environment Variables\n\nIf using environment variables for database connection:\n\n```bash\n# In .env file\nORACLE_USER=report_user\nORACLE_PASSWORD=your_secure_password\nORACLE_HOST=oracle-db\nORACLE_PORT=1521\nORACLE_SERVICE=XEPDB1\n```\n\n## Verification\n\nTo verify everything is working:\n\n```python\nfrom utils.user_management import get_user_info\n\n# Get user information\nuser = get_user_info(username='admin')\nif user:\n    print(f\"User: {user['username']}\")\n    print(f\"Email: {user['email']}\")\n    print(f\"Roles: {[r['role_name'] for r in user['roles']]}\")\n    print(f\"Active: {user['is_active']}\")\n```\n\n## Support\n\nIf you encounter any issues:\n1. Check the Airflow logs: `docker-compose logs airflow-webserver`\n2. Check Oracle logs: `docker-compose logs oracle-db`\n3. Verify database connectivity with DBeaver\n4. Ensure all required Python packages are installed\n","size_bytes":7987},"utils/user_management.py":{"content":"\"\"\"\nUser Management Utilities for Report Microservice\nProvides functions for user authentication and management with secure password hashing\n\"\"\"\n\nimport logging\nimport re\nfrom datetime import datetime\nfrom typing import Optional, Dict, List, Any\nimport bcrypt\nimport oracledb\nfrom airflow.models import Variable\n\nfrom utils.oracle_db_utils import get_db_connection\n\nlogger = logging.getLogger(\"user_management\")\n\n\ndef hash_password(password: str) -> str:\n    \"\"\"\n    Hash a password using bcrypt\n    \n    Args:\n        password: Plain text password to hash\n        \n    Returns:\n        Hashed password as a string\n    \"\"\"\n    # Generate salt and hash the password\n    salt = bcrypt.gensalt(rounds=12)  # 12 rounds is a good balance of security and performance\n    hashed = bcrypt.hashpw(password.encode('utf-8'), salt)\n    return hashed.decode('utf-8')\n\n\ndef verify_password(password: str, password_hash: str) -> bool:\n    \"\"\"\n    Verify a password against its hash\n    \n    Args:\n        password: Plain text password to verify\n        password_hash: Hashed password to compare against\n        \n    Returns:\n        True if password matches, False otherwise\n    \"\"\"\n    try:\n        return bcrypt.checkpw(password.encode('utf-8'), password_hash.encode('utf-8'))\n    except Exception as e:\n        logger.error(f\"Error verifying password: {str(e)}\")\n        return False\n\n\ndef validate_password_strength(password: str) -> tuple[bool, str]:\n    \"\"\"\n    Validate password meets security requirements\n    \n    Requirements:\n    - At least 8 characters long\n    - Contains at least one uppercase letter\n    - Contains at least one lowercase letter\n    - Contains at least one digit\n    - Contains at least one special character\n    \n    Args:\n        password: Password to validate\n        \n    Returns:\n        Tuple of (is_valid, error_message)\n    \"\"\"\n    if len(password) < 8:\n        return False, \"Password must be at least 8 characters long\"\n    \n    if not re.search(r'[A-Z]', password):\n        return False, \"Password must contain at least one uppercase letter\"\n    \n    if not re.search(r'[a-z]', password):\n        return False, \"Password must contain at least one lowercase letter\"\n    \n    if not re.search(r'\\d', password):\n        return False, \"Password must contain at least one digit\"\n    \n    if not re.search(r'[!@#$%^&*()_+\\-=\\[\\]{};:\\'\",.<>?/\\\\|`~]', password):\n        return False, \"Password must contain at least one special character\"\n    \n    return True, \"\"\n\n\ndef validate_email(email: str) -> bool:\n    \"\"\"\n    Validate email format\n    \n    Args:\n        email: Email address to validate\n        \n    Returns:\n        True if valid, False otherwise\n    \"\"\"\n    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n    return bool(re.match(pattern, email))\n\n\ndef create_user(username: str, email: str, password: str, first_name: str = None,\n                last_name: str = None, roles: List[str] = None, created_by: str = 'SYSTEM',\n                must_change_password: bool = False) -> Optional[int]:\n    \"\"\"\n    Create a new user with hashed password\n    \n    Args:\n        username: Unique username\n        email: User's email address\n        password: Plain text password (will be hashed)\n        first_name: User's first name\n        last_name: User's last name\n        roles: List of role IDs to assign to the user\n        created_by: Username of the person creating this user\n        must_change_password: Whether user must change password on first login\n        \n    Returns:\n        User ID if successful, None otherwise\n    \"\"\"\n    connection = None\n    try:\n        # Validate inputs\n        if not username or not email or not password:\n            logger.error(\"Username, email, and password are required\")\n            return None\n        \n        # Validate email format\n        if not validate_email(email):\n            logger.error(f\"Invalid email format: {email}\")\n            return None\n        \n        # Validate password strength\n        is_valid, error_msg = validate_password_strength(password)\n        if not is_valid:\n            logger.error(f\"Password validation failed: {error_msg}\")\n            return None\n        \n        # Hash the password\n        password_hash = hash_password(password)\n        \n        # Get database connection\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        # Check if username already exists\n        cursor.execute(\"SELECT COUNT(*) FROM users WHERE username = :username\", \n                      username=username)\n        if cursor.fetchone()[0] > 0:\n            logger.error(f\"Username already exists: {username}\")\n            cursor.close()\n            return None\n        \n        # Check if email already exists\n        cursor.execute(\"SELECT COUNT(*) FROM users WHERE email = :email\", \n                      email=email)\n        if cursor.fetchone()[0] > 0:\n            logger.error(f\"Email already exists: {email}\")\n            cursor.close()\n            return None\n        \n        # Insert the user\n        cursor.execute(\"\"\"\n            INSERT INTO users \n                (username, email, password_hash, first_name, last_name, \n                 must_change_password, created_by)\n            VALUES \n                (:username, :email, :password_hash, :first_name, :last_name,\n                 :must_change_password, :created_by)\n            RETURNING user_id INTO :user_id\n        \"\"\", username=username, email=email, password_hash=password_hash,\n             first_name=first_name, last_name=last_name,\n             must_change_password=1 if must_change_password else 0,\n             created_by=created_by, user_id=cursor.var(oracledb.NUMBER))\n        \n        user_id = int(cursor.getvalue(0))\n        \n        # Assign roles if provided\n        if roles:\n            for role_id in roles:\n                try:\n                    cursor.execute(\"\"\"\n                        INSERT INTO user_roles (user_id, role_id, assigned_by)\n                        VALUES (:user_id, :role_id, :assigned_by)\n                    \"\"\", user_id=user_id, role_id=role_id, assigned_by=created_by)\n                except oracledb.IntegrityError:\n                    logger.warning(f\"Role {role_id} does not exist or already assigned\")\n        \n        # Log the activity\n        log_user_activity(\n            user_id=user_id,\n            username=username,\n            activity_type='USER_CREATED',\n            activity_description=f'User {username} created by {created_by}',\n            success=True\n        )\n        \n        connection.commit()\n        cursor.close()\n        \n        logger.info(f\"Successfully created user: {username} (ID: {user_id})\")\n        return user_id\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error creating user: {error}\")\n        if connection:\n            connection.rollback()\n        return None\n    finally:\n        if connection:\n            connection.close()\n\n\ndef authenticate_user(username: str, password: str, ip_address: str = None,\n                     user_agent: str = None) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Authenticate a user with username and password\n    \n    Args:\n        username: Username to authenticate\n        password: Plain text password\n        ip_address: IP address of the login attempt\n        user_agent: User agent string of the client\n        \n    Returns:\n        User information dictionary if successful, None otherwise\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        # Get user information\n        cursor.execute(\"\"\"\n            SELECT user_id, username, email, password_hash, first_name, last_name,\n                   is_active, is_locked, failed_login_attempts, must_change_password\n            FROM users\n            WHERE username = :username\n        \"\"\", username=username)\n        \n        row = cursor.fetchone()\n        \n        if not row:\n            logger.warning(f\"Authentication failed: User not found - {username}\")\n            log_user_activity(\n                username=username,\n                activity_type='LOGIN_FAILED',\n                activity_description='User not found',\n                ip_address=ip_address,\n                user_agent=user_agent,\n                success=False,\n                error_message='User not found'\n            )\n            return None\n        \n        user_id, db_username, email, password_hash, first_name, last_name, \\\n            is_active, is_locked, failed_attempts, must_change_password = row\n        \n        # Check if account is active\n        if not is_active:\n            logger.warning(f\"Authentication failed: Account inactive - {username}\")\n            log_user_activity(\n                user_id=user_id,\n                username=username,\n                activity_type='LOGIN_FAILED',\n                activity_description='Account inactive',\n                ip_address=ip_address,\n                user_agent=user_agent,\n                success=False,\n                error_message='Account is inactive'\n            )\n            return None\n        \n        # Check if account is locked\n        if is_locked:\n            logger.warning(f\"Authentication failed: Account locked - {username}\")\n            log_user_activity(\n                user_id=user_id,\n                username=username,\n                activity_type='LOGIN_FAILED',\n                activity_description='Account locked',\n                ip_address=ip_address,\n                user_agent=user_agent,\n                success=False,\n                error_message='Account is locked'\n            )\n            return None\n        \n        # Verify password\n        if not verify_password(password, password_hash):\n            # Increment failed login attempts\n            failed_attempts += 1\n            lock_account = failed_attempts >= 5\n            \n            cursor.execute(\"\"\"\n                UPDATE users\n                SET failed_login_attempts = :failed_attempts,\n                    is_locked = :is_locked\n                WHERE user_id = :user_id\n            \"\"\", failed_attempts=failed_attempts, \n                 is_locked=1 if lock_account else 0,\n                 user_id=user_id)\n            \n            connection.commit()\n            \n            logger.warning(f\"Authentication failed: Invalid password - {username} \"\n                         f\"(Attempts: {failed_attempts})\")\n            \n            log_user_activity(\n                user_id=user_id,\n                username=username,\n                activity_type='LOGIN_FAILED',\n                activity_description=f'Invalid password (Attempt {failed_attempts})',\n                ip_address=ip_address,\n                user_agent=user_agent,\n                success=False,\n                error_message='Invalid password'\n            )\n            \n            if lock_account:\n                logger.warning(f\"Account locked due to too many failed attempts: {username}\")\n            \n            return None\n        \n        # Successful authentication - reset failed attempts and update last login\n        cursor.execute(\"\"\"\n            UPDATE users\n            SET failed_login_attempts = 0,\n                last_login_date = SYSTIMESTAMP\n            WHERE user_id = :user_id\n        \"\"\", user_id=user_id)\n        \n        # Get user roles\n        cursor.execute(\"\"\"\n            SELECT r.role_id, r.role_name, r.description\n            FROM roles r\n            JOIN user_roles ur ON r.role_id = ur.role_id\n            WHERE ur.user_id = :user_id AND r.is_active = 1\n        \"\"\", user_id=user_id)\n        \n        roles = [{'role_id': row[0], 'role_name': row[1], 'description': row[2]} \n                for row in cursor.fetchall()]\n        \n        connection.commit()\n        cursor.close()\n        \n        # Log successful login\n        log_user_activity(\n            user_id=user_id,\n            username=username,\n            activity_type='LOGIN_SUCCESS',\n            activity_description='User logged in successfully',\n            ip_address=ip_address,\n            user_agent=user_agent,\n            success=True\n        )\n        \n        logger.info(f\"User authenticated successfully: {username}\")\n        \n        return {\n            'user_id': user_id,\n            'username': db_username,\n            'email': email,\n            'first_name': first_name,\n            'last_name': last_name,\n            'roles': roles,\n            'must_change_password': bool(must_change_password)\n        }\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error during authentication: {error}\")\n        if connection:\n            connection.rollback()\n        return None\n    finally:\n        if connection:\n            connection.close()\n\n\ndef change_password(user_id: int, old_password: str, new_password: str) -> bool:\n    \"\"\"\n    Change a user's password\n    \n    Args:\n        user_id: User ID\n        old_password: Current password (for verification)\n        new_password: New password\n        \n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    connection = None\n    try:\n        # Validate new password strength\n        is_valid, error_msg = validate_password_strength(new_password)\n        if not is_valid:\n            logger.error(f\"Password validation failed: {error_msg}\")\n            return False\n        \n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        # Get current password hash\n        cursor.execute(\"\"\"\n            SELECT password_hash, username\n            FROM users\n            WHERE user_id = :user_id\n        \"\"\", user_id=user_id)\n        \n        row = cursor.fetchone()\n        if not row:\n            logger.error(f\"User not found: {user_id}\")\n            return False\n        \n        current_hash, username = row\n        \n        # Verify old password\n        if not verify_password(old_password, current_hash):\n            logger.warning(f\"Password change failed: Invalid current password for user {username}\")\n            log_user_activity(\n                user_id=user_id,\n                username=username,\n                activity_type='PASSWORD_CHANGE_FAILED',\n                activity_description='Invalid current password',\n                success=False,\n                error_message='Current password is incorrect'\n            )\n            return False\n        \n        # Hash new password\n        new_hash = hash_password(new_password)\n        \n        # Update password\n        cursor.execute(\"\"\"\n            UPDATE users\n            SET password_hash = :new_hash,\n                password_changed_date = SYSTIMESTAMP,\n                must_change_password = 0,\n                modified_date = SYSTIMESTAMP\n            WHERE user_id = :user_id\n        \"\"\", new_hash=new_hash, user_id=user_id)\n        \n        connection.commit()\n        cursor.close()\n        \n        # Log activity\n        log_user_activity(\n            user_id=user_id,\n            username=username,\n            activity_type='PASSWORD_CHANGED',\n            activity_description='Password changed successfully',\n            success=True\n        )\n        \n        logger.info(f\"Password changed successfully for user: {username}\")\n        return True\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error changing password: {error}\")\n        if connection:\n            connection.rollback()\n        return False\n    finally:\n        if connection:\n            connection.close()\n\n\ndef reset_password(user_id: int, new_password: str, reset_by: str = 'SYSTEM') -> bool:\n    \"\"\"\n    Reset a user's password (admin function)\n    \n    Args:\n        user_id: User ID\n        new_password: New password\n        reset_by: Username of the person resetting the password\n        \n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    connection = None\n    try:\n        # Validate new password strength\n        is_valid, error_msg = validate_password_strength(new_password)\n        if not is_valid:\n            logger.error(f\"Password validation failed: {error_msg}\")\n            return False\n        \n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        # Get username\n        cursor.execute(\"SELECT username FROM users WHERE user_id = :user_id\", \n                      user_id=user_id)\n        row = cursor.fetchone()\n        if not row:\n            logger.error(f\"User not found: {user_id}\")\n            return False\n        \n        username = row[0]\n        \n        # Hash new password\n        new_hash = hash_password(new_password)\n        \n        # Update password and force password change on next login\n        cursor.execute(\"\"\"\n            UPDATE users\n            SET password_hash = :new_hash,\n                password_changed_date = SYSTIMESTAMP,\n                must_change_password = 1,\n                failed_login_attempts = 0,\n                is_locked = 0,\n                modified_date = SYSTIMESTAMP,\n                modified_by = :reset_by\n            WHERE user_id = :user_id\n        \"\"\", new_hash=new_hash, user_id=user_id, reset_by=reset_by)\n        \n        connection.commit()\n        cursor.close()\n        \n        # Log activity\n        log_user_activity(\n            user_id=user_id,\n            username=username,\n            activity_type='PASSWORD_RESET',\n            activity_description=f'Password reset by {reset_by}',\n            success=True\n        )\n        \n        logger.info(f\"Password reset successfully for user: {username} by {reset_by}\")\n        return True\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error resetting password: {error}\")\n        if connection:\n            connection.rollback()\n        return False\n    finally:\n        if connection:\n            connection.close()\n\n\ndef assign_role(user_id: int, role_id: str, assigned_by: str = 'SYSTEM') -> bool:\n    \"\"\"\n    Assign a role to a user\n    \n    Args:\n        user_id: User ID\n        role_id: Role ID to assign\n        assigned_by: Username of the person assigning the role\n        \n    Returns:\n        True if successful, False otherwise\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        # Get username\n        cursor.execute(\"SELECT username FROM users WHERE user_id = :user_id\", \n                      user_id=user_id)\n        row = cursor.fetchone()\n        if not row:\n            logger.error(f\"User not found: {user_id}\")\n            return False\n        \n        username = row[0]\n        \n        # Assign role\n        cursor.execute(\"\"\"\n            INSERT INTO user_roles (user_id, role_id, assigned_by)\n            VALUES (:user_id, :role_id, :assigned_by)\n        \"\"\", user_id=user_id, role_id=role_id, assigned_by=assigned_by)\n        \n        connection.commit()\n        cursor.close()\n        \n        # Log activity\n        log_user_activity(\n            user_id=user_id,\n            username=username,\n            activity_type='ROLE_ASSIGNED',\n            activity_description=f'Role {role_id} assigned by {assigned_by}',\n            success=True\n        )\n        \n        logger.info(f\"Role {role_id} assigned to user {username} by {assigned_by}\")\n        return True\n        \n    except oracledb.IntegrityError:\n        logger.warning(f\"Role assignment failed: Role {role_id} already assigned to user {user_id}\")\n        return False\n    except oracledb.Error as error:\n        logger.error(f\"Database error assigning role: {error}\")\n        if connection:\n            connection.rollback()\n        return False\n    finally:\n        if connection:\n            connection.close()\n\n\ndef log_user_activity(user_id: int = None, username: str = None, activity_type: str = None,\n                     activity_description: str = None, ip_address: str = None,\n                     user_agent: str = None, success: bool = True, \n                     error_message: str = None):\n    \"\"\"\n    Log user activity\n    \n    Args:\n        user_id: User ID (optional if user doesn't exist yet)\n        username: Username\n        activity_type: Type of activity\n        activity_description: Description of the activity\n        ip_address: IP address of the client\n        user_agent: User agent string\n        success: Whether the activity was successful\n        error_message: Error message if failed\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        cursor.execute(\"\"\"\n            INSERT INTO user_activity_log \n                (user_id, username, activity_type, activity_description,\n                 ip_address, user_agent, success, error_message)\n            VALUES \n                (:user_id, :username, :activity_type, :activity_description,\n                 :ip_address, :user_agent, :success, :error_message)\n        \"\"\", user_id=user_id, username=username, activity_type=activity_type,\n             activity_description=activity_description, ip_address=ip_address,\n             user_agent=user_agent, success=1 if success else 0, \n             error_message=error_message)\n        \n        connection.commit()\n        cursor.close()\n        \n    except oracledb.Error as error:\n        logger.error(f\"Error logging user activity: {error}\")\n        if connection:\n            connection.rollback()\n    finally:\n        if connection:\n            connection.close()\n\n\ndef get_user_info(user_id: int = None, username: str = None) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    Get detailed user information\n    \n    Args:\n        user_id: User ID (if provided, username is ignored)\n        username: Username\n        \n    Returns:\n        User information dictionary or None\n    \"\"\"\n    connection = None\n    try:\n        connection = get_db_connection()\n        cursor = connection.cursor()\n        \n        if user_id:\n            cursor.execute(\"\"\"\n                SELECT user_id, username, email, first_name, last_name,\n                       is_active, is_locked, last_login_date, password_changed_date,\n                       must_change_password, created_date\n                FROM users\n                WHERE user_id = :user_id\n            \"\"\", user_id=user_id)\n        else:\n            cursor.execute(\"\"\"\n                SELECT user_id, username, email, first_name, last_name,\n                       is_active, is_locked, last_login_date, password_changed_date,\n                       must_change_password, created_date\n                FROM users\n                WHERE username = :username\n            \"\"\", username=username)\n        \n        row = cursor.fetchone()\n        if not row:\n            return None\n        \n        user_info = {\n            'user_id': row[0],\n            'username': row[1],\n            'email': row[2],\n            'first_name': row[3],\n            'last_name': row[4],\n            'is_active': bool(row[5]),\n            'is_locked': bool(row[6]),\n            'last_login_date': row[7].isoformat() if row[7] else None,\n            'password_changed_date': row[8].isoformat() if row[8] else None,\n            'must_change_password': bool(row[9]),\n            'created_date': row[10].isoformat() if row[10] else None\n        }\n        \n        # Get roles\n        cursor.execute(\"\"\"\n            SELECT r.role_id, r.role_name, r.description\n            FROM roles r\n            JOIN user_roles ur ON r.role_id = ur.role_id\n            WHERE ur.user_id = :user_id AND r.is_active = 1\n        \"\"\", user_id=user_info['user_id'])\n        \n        user_info['roles'] = [\n            {'role_id': row[0], 'role_name': row[1], 'description': row[2]}\n            for row in cursor.fetchall()\n        ]\n        \n        cursor.close()\n        return user_info\n        \n    except oracledb.Error as error:\n        logger.error(f\"Database error getting user info: {error}\")\n        return None\n    finally:\n        if connection:\n            connection.close()\n","size_bytes":24044},"USER_MANAGEMENT_QUICK_REFERENCE.md":{"content":"# User Management Quick Reference\n\n## Common Operations\n\n### Create a User\n```python\nfrom utils.user_management import create_user\n\nuser_id = create_user(\n    username='john_doe',\n    email='john@example.com',\n    password='SecurePass123!',\n    first_name='John',\n    last_name='Doe',\n    roles=['REPORT_VIEWER'],\n    created_by='admin'\n)\n```\n\n### Authenticate User\n```python\nfrom utils.user_management import authenticate_user\n\nuser = authenticate_user(\n    username='john_doe',\n    password='SecurePass123!',\n    ip_address='192.168.1.100'\n)\n```\n\n### Change Password\n```python\nfrom utils.user_management import change_password\n\nsuccess = change_password(\n    user_id=123,\n    old_password='OldPass123!',\n    new_password='NewPass456!'\n)\n```\n\n### Reset Password (Admin)\n```python\nfrom utils.user_management import reset_password\n\nsuccess = reset_password(\n    user_id=123,\n    new_password='TempPass123!',\n    reset_by='admin'\n)\n```\n\n### Assign Role to User\n```python\nfrom utils.user_management import assign_role\n\nsuccess = assign_role(\n    user_id=123,\n    role_id='REPORT_MANAGER',\n    assigned_by='admin'\n)\n```\n\n### Get User Information\n```python\nfrom utils.user_management import get_user_info\n\n# By user ID\nuser = get_user_info(user_id=123)\n\n# By username\nuser = get_user_info(username='john_doe')\n```\n\n### Log User Activity\n```python\nfrom utils.user_management import log_user_activity\n\nlog_user_activity(\n    user_id=123,\n    username='john_doe',\n    activity_type='REPORT_EXECUTED',\n    activity_description='Executed daily sales report',\n    ip_address='192.168.1.100',\n    success=True\n)\n```\n\n## Available Roles\n\n| Role ID | Role Name | Permissions |\n|---------|-----------|-------------|\n| ADMIN | Administrator | Full access (view, execute, modify, delete) |\n| REPORT_MANAGER | Report Manager | View, execute, modify reports |\n| REPORT_VIEWER | Report Viewer | View and execute reports |\n| REPORT_EXECUTOR | Report Executor | View and execute reports |\n\n## Password Requirements\n\n✓ Minimum 8 characters  \n✓ At least one uppercase letter  \n✓ At least one lowercase letter  \n✓ At least one digit  \n✓ At least one special character  \n\nExamples of valid passwords:\n- `SecurePass123!`\n- `MyP@ssw0rd`\n- `Admin#2024`\n\n## Activity Types for Logging\n\nCommon activity types:\n- `USER_CREATED` - New user account created\n- `LOGIN_SUCCESS` - Successful login\n- `LOGIN_FAILED` - Failed login attempt\n- `PASSWORD_CHANGED` - Password changed by user\n- `PASSWORD_RESET` - Password reset by admin\n- `ROLE_ASSIGNED` - Role assigned to user\n- `REPORT_EXECUTED` - Report executed by user\n- `REPORT_CREATED` - New report created\n- `REPORT_MODIFIED` - Report configuration changed\n- `REPORT_DELETED` - Report deleted\n\n## SQL Queries for User Management\n\n### View All Users\n```sql\nSELECT user_id, username, email, first_name, last_name, is_active, is_locked\nFROM users\nORDER BY username;\n```\n\n### View User Roles\n```sql\nSELECT u.username, r.role_name, r.description\nFROM users u\nJOIN user_roles ur ON u.user_id = ur.user_id\nJOIN roles r ON ur.role_id = r.role_id\nWHERE u.username = 'john_doe';\n```\n\n### View Recent User Activity\n```sql\nSELECT username, activity_type, activity_description, \n       timestamp, success, ip_address\nFROM user_activity_log\nWHERE username = 'john_doe'\nORDER BY timestamp DESC\nFETCH FIRST 10 ROWS ONLY;\n```\n\n### View Failed Login Attempts\n```sql\nSELECT username, activity_description, timestamp, \n       ip_address, error_message\nFROM user_activity_log\nWHERE activity_type = 'LOGIN_FAILED'\n  AND timestamp > SYSTIMESTAMP - INTERVAL '1' DAY\nORDER BY timestamp DESC;\n```\n\n### View Locked Accounts\n```sql\nSELECT user_id, username, email, failed_login_attempts, last_login_date\nFROM users\nWHERE is_locked = 1;\n```\n\n### Unlock a User Account\n```sql\nUPDATE users\nSET is_locked = 0,\n    failed_login_attempts = 0\nWHERE username = 'john_doe';\nCOMMIT;\n```\n\n### View Report Permissions by Role\n```sql\nSELECT r.role_name, rc.report_name,\n       rp.can_view, rp.can_execute, rp.can_modify, rp.can_delete\nFROM report_permissions rp\nJOIN roles r ON rp.role_id = r.role_id\nJOIN report_configs rc ON rp.report_id = rc.report_id\nORDER BY r.role_name, rc.report_name;\n```\n\n## CLI Commands\n\n### Create Initial Admin User\n```bash\ndocker exec -it airflow-webserver python /opt/airflow/create_admin_user.py\n```\n\n### Run SQL Script Manually\n```bash\ndocker exec -i oracle-db sqlplus report_user/report_password@XEPDB1 < 02_create_user_tables.sql\n```\n\n### Check User Tables Exist\n```bash\ndocker exec -it oracle-db sqlplus -S report_user/report_password@XEPDB1 << EOF\nSELECT table_name FROM user_tables \nWHERE table_name IN ('USERS', 'ROLES', 'USER_ROLES', 'REPORT_PERMISSIONS', 'USER_ACTIVITY_LOG');\nEXIT;\nEOF\n```\n\n## Error Messages\n\n| Error | Cause | Solution |\n|-------|-------|----------|\n| \"Username already exists\" | Duplicate username | Use a different username |\n| \"Email already exists\" | Duplicate email | Use a different email |\n| \"Password validation failed\" | Password too weak | Follow password requirements |\n| \"User not found\" | Invalid user ID/username | Verify user exists |\n| \"Invalid current password\" | Wrong password in change | Check current password |\n| \"Account is locked\" | Too many failed logins | Unlock account via SQL or admin |\n| \"Account is inactive\" | User deactivated | Activate user account |\n| \"Role does not exist\" | Invalid role ID | Use one of: ADMIN, REPORT_MANAGER, REPORT_VIEWER, REPORT_EXECUTOR |\n\n## Testing Authentication\n\n### Python Test Script\n```python\nfrom utils.user_management import (\n    create_user, authenticate_user, \n    change_password, get_user_info\n)\n\n# Create test user\nuser_id = create_user(\n    username='test_user',\n    email='test@example.com',\n    password='TestPass123!',\n    roles=['REPORT_VIEWER']\n)\nprint(f\"Created user ID: {user_id}\")\n\n# Authenticate\nuser = authenticate_user('test_user', 'TestPass123!')\nprint(f\"Authenticated: {user['username']}\")\n\n# Get info\ninfo = get_user_info(username='test_user')\nprint(f\"User roles: {[r['role_name'] for r in info['roles']]}\")\n\n# Change password\nsuccess = change_password(user_id, 'TestPass123!', 'NewPass456!')\nprint(f\"Password changed: {success}\")\n\n# Verify new password\nuser = authenticate_user('test_user', 'NewPass456!')\nprint(f\"New password works: {user is not None}\")\n```\n\n## Security Best Practices\n\n1. **Never log passwords** - The system logs activity but never passwords\n2. **Use strong passwords** - Follow all password requirements\n3. **Rotate admin passwords** - Change admin passwords regularly\n4. **Review activity logs** - Check for suspicious login patterns\n5. **Lock inactive accounts** - Deactivate users who no longer need access\n6. **Use least privilege** - Assign minimum required roles\n7. **Monitor failed logins** - Set up alerts for repeated failures\n8. **Regular audits** - Review user permissions quarterly\n\n## Environment Setup\n\nRequired Python packages:\n```bash\npip install bcrypt cx_Oracle\n```\n\nRequired database tables:\n- users\n- roles  \n- user_roles\n- report_permissions\n- user_activity_log\n\nRequired environment variables:\n```\nORACLE_USER=report_user\nORACLE_PASSWORD=your_password\nORACLE_HOST=oracle-db\nORACLE_PORT=1521\nORACLE_SERVICE=XEPDB1\n```\n","size_bytes":7193},"utils/__init__.py":{"content":"","size_bytes":0},"dags/long_released_orders_report_dag.py":{"content":"# long_released_orders_report_dag.py\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.email import EmailOperator\nfrom airflow.models import Variable\nimport requests\nimport json\nimport pandas as pd\nimport logging\nimport os\nimport sys\nsys.path.append(\"/opt/airflow\")\nfrom utils.report_utils import query_order_api, generate_pdf_report\nfrom reportlab.lib import colors\nfrom reportlab.lib.pagesizes import letter, landscape\nfrom reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\nfrom reportlab.lib.styles import getSampleStyleSheet\nfrom airflow.utils.dates import days_ago\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"long_released_orders_report_service\")\n\n# Define default arguments for the DAG\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 3,\n    'retry_delay': timedelta(minutes=5),\n}\n\n# Function to query orders that have been in released status for more than 72 hours\ndef query_long_released_orders(**kwargs):\n    \"\"\"\n    Query the order search API for orders that have been in released status for more than 72 hours\n    \"\"\"\n    # Get execution date from context\n    execution_date = kwargs['execution_date']\n    \n    # Get API configuration from Airflow Variables\n    api_base_url = Variable.get(\"order_api_base_url\")\n    search_endpoint = f\"{api_base_url}/order/order/search\"\n    \n    # Calculate the time threshold (72 hours ago from execution date)\n    threshold_time = (execution_date - timedelta(hours=72)).strftime(\"%Y-%m-%dT%H:%M:%S\")\n    \n    logger.info(f\"Searching for orders with Released status from before {threshold_time}\")\n    \n    # Build search payload\n    payload = {\n        \"Query\": f\"Order.Status.StatusId = 'Released' AND Order.UpdatedTimestamp < '{threshold_time}'\",\n        \"Template\": {\n            \"OrderId\": None,\n            \"Order\": {\n                \"Status\": {\n                    \"StatusId\": None\n                },\n                \"OrderTypeId\": None,\n                \"CreatedTimestamp\": None,\n                \"UpdatedTimestamp\": None,\n                \"ExpectedDeliveryDate\": None\n            },\n            \"OrderLine\": [\n                {\n                    \"OrderLineId\": None,\n                    \"ItemId\": None,\n                    \"Description\": None,\n                    \"Quantity\": None,\n                    \"Status\": {\n                        \"StatusId\": None\n                    },\n                    \"ShipNode\": {\n                        \"LocationId\": None\n                    }\n                }\n            ],\n            \"Release\": [\n                {\n                    \"ReleaseId\": None,\n                    \"Status\": {\n                        \"StatusId\": None\n                    }\n                }\n            ]\n        },\n        \"Size\": 1000,\n        \"Sort\": [\n            {\n                \"attribute\": \"UpdatedTimestamp\",\n                \"direction\": \"asc\"\n            }\n        ]\n    }\n    \n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {Variable.get('api_token', '')}\"\n    }\n    \n    try:\n        logger.info(\"Executing search query...\")\n        response = requests.post(\n            search_endpoint, \n            json=payload,\n            headers=headers\n        )\n        \n        if response.status_code != 200:\n            logger.error(f\"Error in API call: {response.status_code} - {response.text}\")\n            raise Exception(f\"API returned error: {response.status_code}\")\n        \n        result_data = response.json()\n        \n        # Check if we have results\n        if not result_data or len(result_data) == 0:\n            logger.info(\"No orders found matching the criteria\")\n            all_results = []\n        else:\n            logger.info(f\"Retrieved {len(result_data)} orders that have been in Released status for over 72 hours\")\n            all_results = result_data\n        \n    except Exception as e:\n        logger.error(f\"Error during API search: {str(e)}\")\n        raise\n    \n    # Create a temporary file to store the results\n    result_file = f\"/tmp/long_released_orders_{execution_date.strftime('%Y%m%d')}.json\"\n    with open(result_file, 'w') as f:\n        json.dump(all_results, f)\n    \n    # Return the path to the result file for the next task\n    return result_file\n\n# Function to generate a PDF report from the API results\ndef generate_long_released_report(**kwargs):\n    \"\"\"\n    Generate a PDF report showing orders that have been in Released status for more than 72 hours\n    \"\"\"\n    # Get the task instance\n    ti = kwargs['ti']\n    \n    # Get the result file path from the previous task\n    result_file = ti.xcom_pull(task_ids='query_long_released_orders')\n    execution_date = kwargs['execution_date']\n    \n    logger.info(f\"Generating PDF report from {result_file}\")\n    \n    # Load the results\n    with open(result_file, 'r') as f:\n        results = json.load(f)\n    \n    if not results:\n        logger.warning(\"No results found for report generation\")\n        # Create an empty PDF with a message\n        pdf_file = f\"/tmp/long_released_orders_report_{execution_date.strftime('%Y%m%d')}.pdf\"\n        doc = SimpleDocTemplate(pdf_file, pagesize=letter)\n        styles = getSampleStyleSheet()\n        elements = []\n        elements.append(Paragraph(f\"Long Released Orders Report - {execution_date.strftime('%Y-%m-%d')}\", styles['Title']))\n        elements.append(Spacer(1, 12))\n        elements.append(Paragraph(\"No orders found in Released status for more than 72 hours.\", styles['Normal']))\n        doc.build(elements)\n        return pdf_file\n    \n    # Extract and transform the data for reporting\n    report_data = []\n    \n    # Add header row\n    headers = [\"Order ID\", \"Order Type\", \"Created Date\", \"Last Updated\", \"Status\", \"Days in Released Status\", \"Ship From Locations\"]\n    report_data.append(headers)\n    \n    # Process the data and calculate days in released status\n    for order in results:\n        try:\n            order_id = order.get(\"OrderId\", \"N/A\")\n            order_type = order.get(\"Order\", {}).get(\"OrderTypeId\", \"N/A\")\n            created_timestamp = order.get(\"Order\", {}).get(\"CreatedTimestamp\", \"N/A\")\n            updated_timestamp = order.get(\"Order\", {}).get(\"UpdatedTimestamp\", \"N/A\")\n            status = order.get(\"Order\", {}).get(\"Status\", {}).get(\"StatusId\", \"N/A\")\n            \n            # Calculate days in released status\n            if updated_timestamp != \"N/A\":\n                updated_date = datetime.strptime(updated_timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n                days_in_status = (execution_date - updated_date).days\n            else:\n                days_in_status = \"N/A\"\n            \n            # Extract unique ship from locations\n            ship_nodes = set()\n            for line in order.get(\"OrderLine\", []):\n                if line.get(\"ShipNode\") and line.get(\"ShipNode\").get(\"LocationId\"):\n                    ship_nodes.add(line.get(\"ShipNode\").get(\"LocationId\"))\n            \n            ship_locations = \", \".join(ship_nodes) if ship_nodes else \"N/A\"\n            \n            # Format timestamps for readability\n            if created_timestamp != \"N/A\":\n                created_timestamp = datetime.strptime(created_timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M\")\n            \n            if updated_timestamp != \"N/A\":\n                updated_timestamp = datetime.strptime(updated_timestamp, \"%Y-%m-%dT%H:%M:%S.%fZ\").strftime(\"%Y-%m-%d %H:%M\")\n            \n            row = [\n                order_id,\n                order_type,\n                created_timestamp,\n                updated_timestamp,\n                status,\n                str(days_in_status) if days_in_status != \"N/A\" else \"N/A\",\n                ship_locations\n            ]\n            report_data.append(row)\n        except Exception as e:\n            logger.error(f\"Error processing order data: {str(e)}\")\n            continue\n    \n    # Create a DataFrame for summary statistics\n    df = pd.DataFrame(report_data[1:], columns=report_data[0])\n    if 'Days in Released Status' in df.columns:\n        df['Days in Released Status'] = pd.to_numeric(df['Days in Released Status'], errors='coerce')\n    \n    # Calculate summary statistics\n    total_orders = len(df)\n    avg_days = df['Days in Released Status'].mean() if 'Days in Released Status' in df.columns else 0\n    max_days = df['Days in Released Status'].max() if 'Days in Released Status' in df.columns else 0\n    \n    # Count orders by days in status ranges\n    days_3_to_5 = len(df[(df['Days in Released Status'] >= 3) & (df['Days in Released Status'] < 5)]) if 'Days in Released Status' in df.columns else 0\n    days_5_to_7 = len(df[(df['Days in Released Status'] >= 5) & (df['Days in Released Status'] < 7)]) if 'Days in Released Status' in df.columns else 0\n    days_over_7 = len(df[df['Days in Released Status'] >= 7]) if 'Days in Released Status' in df.columns else 0\n    \n    # Generate the PDF\n    pdf_file = f\"/tmp/long_released_orders_report_{execution_date.strftime('%Y%m%d')}.pdf\"\n    doc = SimpleDocTemplate(pdf_file, pagesize=landscape(letter))\n    \n    styles = getSampleStyleSheet()\n    elements = []\n    \n    # Add title\n    title = f\"Long Released Orders Report - {execution_date.strftime('%Y-%m-%d')}\"\n    elements.append(Paragraph(title, styles['Title']))\n    elements.append(Spacer(1, 12))\n    \n    # Add description\n    description = \"This report shows orders that have been in Released status for more than 72 hours from the time of last status update.\"\n    elements.append(Paragraph(description, styles['Normal']))\n    elements.append(Spacer(1, 12))\n    \n    # Add summary section\n    elements.append(Paragraph(\"Summary\", styles['Heading2']))\n    summary_data = [\n        [\"Total Orders in Released Status >72 Hours\", str(total_orders)],\n        [\"Average Days in Released Status\", f\"{avg_days:.1f}\" if avg_days else \"0\"],\n        [\"Maximum Days in Released Status\", f\"{max_days:.1f}\" if max_days else \"0\"],\n        [\"Orders in Released: 3-5 days\", str(days_3_to_5)],\n        [\"Orders in Released: 5-7 days\", str(days_5_to_7)],\n        [\"Orders in Released: 7+ days\", str(days_over_7)]\n    ]\n    \n    summary_table = Table(summary_data, colWidths=[300, 150])\n    summary_table.setStyle(TableStyle([\n        ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),\n        ('TEXTCOLOR', (0, 0), (0, -1), colors.black),\n        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n        ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),\n        ('BOTTOMPADDING', (0, 0), (-1, -1), 12),\n        ('GRID', (0, 0), (-1, -1), 1, colors.black)\n    ]))\n    elements.append(summary_table)\n    elements.append(Spacer(1, 24))\n    \n    # Add main table\n    elements.append(Paragraph(\"Order Details\", styles['Heading2']))\n    \n    # Create the table\n    table = Table(report_data, repeatRows=1)\n    \n    # Style the table\n    table_style = TableStyle([\n        ('BACKGROUND', (0, 0), (-1, 0), colors.blue),\n        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n        ('ALIGN', (0, 0), (-1, 0), 'CENTER'),\n        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n        ('FONTSIZE', (0, 0), (-1, 0), 12),\n        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n        ('ALIGN', (0, 1), (-1, -1), 'LEFT'),\n        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n        ('FONTSIZE', (0, 1), (-1, -1), 10),\n        ('BOTTOMPADDING', (0, 1), (-1, -1), 8),\n        ('GRID', (0, 0), (-1, -1), 1, colors.black),\n        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n    ])\n    \n    # Add a zebra striping pattern\n    for i in range(1, len(report_data)):\n        if i % 2 == 0:\n            table_style.add('BACKGROUND', (0, i), (-1, i), colors.lightgrey)\n    \n    table.setStyle(table_style)\n    elements.append(table)\n    \n    # Build the PDF\n    doc.build(elements)\n    \n    logger.info(f\"PDF report generated: {pdf_file}\")\n    return pdf_file\n\n# Create the DAG\ndag = DAG(\n    'long_released_orders_report',\n    default_args=default_args,\n    description='Search for orders in Released status for more than 72 hours, generate a PDF report, and email it',\n    schedule_interval='0 6 * * *',  # Run daily at 6:00 AM\n    start_date=days_ago(1),\n    catchup=False,\n    tags=['order', 'report', 'released'],\n)\n\n# Task 1: Query orders in Released status for more than 72 hours\ntask_query_orders = PythonOperator(\n    task_id='query_long_released_orders',\n    python_callable=query_long_released_orders,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 2: Generate the PDF report\ntask_generate_pdf = PythonOperator(\n    task_id='generate_long_released_report',\n    python_callable=generate_long_released_report,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 3: Email the PDF report\ntask_email_report = EmailOperator(\n    task_id='email_report',\n    to=\"{{ var.value.report_recipients }}\",\n    subject=\"Long Released Orders Report - {{ ds }}\",\n    html_content=\"\"\"\n        <p>Hello,</p>\n        <p>Please find attached the report of orders that have been in Released status for more than 72 hours.</p>\n        <p>This report helps identify orders that may require attention due to extended processing time.</p>\n        <p>Best regards,<br/>Automated Reporting System</p>\n    \"\"\",\n    files=[\"{{ ti.xcom_pull(task_ids='generate_long_released_report') }}\"],\n    dag=dag,\n)\n\n# Define task dependencies\ntask_query_orders >> task_generate_pdf >> task_email_report","size_bytes":13621},"dags/report_configuration_dag.py":{"content":"# improved_report_config_dag.py\nfrom datetime import datetime, timedelta\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.providers.http.operators.http import SimpleHttpOperator\nfrom airflow.utils.dates import days_ago\nfrom airflow.models import Variable\nfrom airflow.hooks.base import BaseHook\nimport json\nimport logging\nimport os\nimport sys\nsys.path.append(\"/opt/airflow\")\nfrom utils.report_utils import query_order_api\n\n# Add project root to path for local imports\nsys.path.append(os.path.join(os.path.dirname(__file__), \"..\"))\nfrom utils.report_utils import get_api_auth_token\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\nlogger = logging.getLogger(\"report_config_service\")\n\n# Define default arguments for the DAG\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n\n# Function to update report configurations\ndef update_report_configs(**kwargs):\n    \"\"\"\n    Update report configurations from a configuration file or API\n    \"\"\"\n    try:\n        # Check if we should load from a file instead of hardcoded configs\n        config_path = Variable.get(\"report_config_path\", default_var=None)\n        \n        if config_path and os.path.exists(config_path):\n            logger.info(f\"Loading report configurations from file: {config_path}\")\n            with open(config_path, 'r') as f:\n                report_configs = json.load(f)\n        else:\n            # In a real scenario, this might come from a database or external API\n            # For now, we'll use the hardcoded example configs\n            logger.info(\"Using default hardcoded report configurations\")\n            report_configs = [\n                {\n                    \"report_id\": \"daily_order_summary\",\n                    \"name\": \"Daily Order Summary\",\n                    \"description\": \"Summary of all orders processed in the last 24 hours\",\n                    \"schedule\": \"0 8 * * *\",\n                    \"query_parameters\": {\n                        \"order_type\": \"StandardOrder\",\n                        \"view_name\": \"orderdetails\",\n                        \"sort_field\": \"OrderDate\"\n                    },\n                    \"email\": {\n                        \"recipients\": [\"team@example.com\", \"managers@example.com\"],\n                        \"subject\": \"Daily Order Summary - {date}\",\n                        \"body\": \"Please find attached the daily order summary report.\"\n                    },\n                    \"report_fields\": [\n                        \"OrderId\", \"OrderDate\", \"CustomerName\", \"Status\", \"TotalItems\", \"TotalValue\"\n                    ],\n                    \"summary_fields\": [\n                        {\"field\": \"TotalValue\", \"operation\": \"sum\", \"label\": \"Total Revenue\"},\n                        {\"field\": \"TotalItems\", \"operation\": \"sum\", \"label\": \"Total Items\"},\n                        {\"field\": \"OrderId\", \"operation\": \"count\", \"label\": \"Order Count\"}\n                    ],\n                    \"active\": True\n                },\n                {\n                    \"report_id\": \"exception_orders\",\n                    \"name\": \"Exception Orders Report\",\n                    \"description\": \"Orders with exceptions or errors\",\n                    \"schedule\": \"0 9 * * *\",\n                    \"query_parameters\": {\n                        \"order_type\": \"ExceptionOrder\",\n                        \"view_name\": \"orderdetails\",\n                        \"sort_field\": \"OrderDate\"\n                    },\n                    \"email\": {\n                        \"recipients\": [\"exceptions@example.com\", \"support@example.com\"],\n                        \"subject\": \"Exception Orders Report - {date}\",\n                        \"body\": \"Please find attached the exception orders report that requires attention.\"\n                    },\n                    \"report_fields\": [\n                        \"OrderId\", \"OrderDate\", \"CustomerName\", \"ExceptionCode\", \"ExceptionDesc\", \"PriorityLevel\"\n                    ],\n                    \"summary_fields\": [\n                        {\"field\": \"ExceptionCode\", \"operation\": \"group\", \"label\": \"Exceptions by Type\"},\n                        {\"field\": \"PriorityLevel\", \"operation\": \"group\", \"label\": \"Exceptions by Priority\"}\n                    ],\n                    \"active\": True\n                }\n            ]\n        \n        # Validate configurations\n        validated_configs = []\n        for config in report_configs:\n            # Check required fields\n            required_fields = [\"report_id\", \"name\", \"query_parameters\"]\n            if all(field in config for field in required_fields):\n                validated_configs.append(config)\n            else:\n                missing = [field for field in required_fields if field not in config]\n                logger.warning(f\"Skipping invalid config missing fields: {missing}\")\n        \n        # Store each configuration as a separate variable\n        for config in validated_configs:\n            Variable.set(\n                f\"report_config_{config['report_id']}\", \n                json.dumps(config),\n                serialize_json=True\n            )\n            logger.info(f\"Updated configuration for report: {config['report_id']}\")\n        \n        # Store the list of available reports\n        report_ids = [config[\"report_id\"] for config in validated_configs if config.get(\"active\", True)]\n        Variable.set(\"active_report_ids\", json.dumps(report_ids), serialize_json=True)\n        \n        # Log summary\n        logger.info(f\"Configuration update complete. {len(validated_configs)} configurations processed, {len(report_ids)} active.\")\n        return report_ids\n        \n    except Exception as e:\n        logger.error(f\"Error updating report configurations: {str(e)}\")\n        raise\n\n# Function to set up API connection\ndef setup_api_connection(**kwargs):\n    \"\"\"\n    Set up the API connection parameters and get an auth token\n    \"\"\"\n    try:\n        # Check if connection exists in Airflow connections\n        conn_id = \"order_api\"\n        try:\n            conn = BaseHook.get_connection(conn_id)\n            logger.info(f\"Using existing connection: {conn_id}\")\n            \n            # Set Variables from connection\n            api_base_url = conn.host\n            if api_base_url.startswith(('http://', 'https://')):\n                Variable.set(\"order_api_base_url\", api_base_url)\n            else:\n                Variable.set(\"order_api_base_url\", f\"https://{api_base_url}\")\n                \n            # Store credentials\n            Variable.set(\"api_client_id\", conn.login)\n            Variable.set(\"api_client_secret\", conn.password)\n            \n        except:\n            logger.warning(f\"Connection {conn_id} not found, using environment variables or defaults\")\n            \n            # Use environment variables or defaults\n            api_base_url = os.environ.get(\"ORDER_API_BASE_URL\", \"https://api.example.com\")\n            Variable.set(\"order_api_base_url\", api_base_url)\n            \n            # Use environment variables for credentials\n            Variable.set(\"api_client_id\", os.environ.get(\"ORDER_API_CLIENT_ID\", \"default_client_id\"))\n            Variable.set(\"api_client_secret\", os.environ.get(\"ORDER_API_CLIENT_SECRET\", \"default_client_secret\"))\n        \n        # Get an initial auth token\n        token = get_api_auth_token()\n        logger.info(\"Successfully acquired API authentication token\")\n        \n        # Set default report recipients if not set\n        if not Variable.get(\"default_report_recipients\", default_var=None):\n            Variable.set(\"default_report_recipients\", \"admin@example.com\")\n        \n        return True\n        \n    except Exception as e:\n        logger.error(f\"Error setting up API connection: {str(e)}\")\n        return False\n\n# Function to test API connectivity\ndef test_api_connectivity(**kwargs):\n    \"\"\"\n    Test the connectivity to the order search API\n    \"\"\"\n    api_base_url = Variable.get(\"order_api_base_url\")\n    test_endpoint = f\"{api_base_url}/health\"\n    \n    try:\n        import requests\n        \n        # Get token for authentication\n        token = get_api_auth_token()\n        \n        headers = {\n            \"Authorization\": f\"Bearer {token}\"\n        }\n        \n        response = requests.get(test_endpoint, headers=headers)\n        \n        if response.status_code == 200:\n            logger.info(\"API connectivity test successful\")\n            return True\n        else:\n            logger.error(f\"API connectivity test failed: {response.status_code} - {response.text}\")\n            return False\n    except Exception as e:\n        logger.error(f\"API connectivity test exception: {str(e)}\")\n        return False\n\n# Create the DAG\ndag = DAG(\n    'report_configuration_manager',\n    default_args=default_args,\n    description='Manage and update report configurations',\n    schedule_interval='@daily',  # Run once per day\n    start_date=days_ago(1),\n    catchup=False,\n    tags=['config', 'report'],\n)\n\n# Task 1: Set up API connection\ntask_setup_api = PythonOperator(\n    task_id='setup_api_connection',\n    python_callable=setup_api_connection,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 2: Update report configurations\ntask_update_configs = PythonOperator(\n    task_id='update_report_configs',\n    python_callable=update_report_configs,\n    provide_context=True,\n    dag=dag,\n)\n\n# Task 3: Test API connectivity\ntask_test_api = PythonOperator(\n    task_id='test_api_connectivity',\n    python_callable=test_api_connectivity,\n    provide_context=True,\n    dag=dag,\n)\n\n# Define task dependencies\ntask_setup_api >> task_update_configs >> task_test_api","size_bytes":9810},"utils/report_utils.py":{"content":"def query_order_api(from_date, to_date, report_config=None):\n    \"\"\"\n    Query the order search API with configurable parameters and log response to MongoDB\n    \n    Args:\n        from_date (str): Start date in format \"DD MMM YYYY\"\n        to_date (str): End date in format \"DD MMM YYYY\"\n        report_config (dict, optional): Report configuration with query parameters\n        \n    Returns:\n        list: Order data results\n    \"\"\"\n    # Import the MongoDB utilities - put this inside the function to avoid\n    # import errors if mongo_utils isn't available\n    try:\n        from utils.mongo_utils import log_api_response\n        mongo_available = True\n    except ImportError:\n        logger.warning(\"MongoDB utilities not available. API responses will not be logged.\")\n        mongo_available = False\n    \n    # Get API configuration\n    api_base_url = Variable.get(\"order_api_base_url\")\n    search_endpoint = f\"{api_base_url}/order/search\"\n    \n    # Get token for authentication\n    token = get_api_auth_token()\n    \n    # Build default search payload\n    payload = {\n        \"ViewName\": \"orderdetails\",\n        \"Filters\": [\n            {\n                \"ViewName\": \"orderdetails\",\n                \"AttributeId\": \"OrderDate\",\n                \"DataType\": None,\n                \"requiredFilter\": False,\n                \"FilterValues\": [\n                    {\n                        \"filter\": {\n                            \"date\": {\n                                \"from\": from_date,\n                                \"to\": to_date\n                            },\n                            \"time\": {\n                                \"from\": \"00:00\",\n                                \"to\": \"23:59\",\n                                \"start\": 0,\n                                \"end\": 288\n                            },\n                            \"quickSelect\": \"CUSTOM\"\n                        }\n                    }\n                ],\n                \"negativeFilter\": False\n            }\n        ],\n        \"RequestAttributeIds\": [],\n        \"SearchOptions\": [],\n        \"SearchChains\": [],\n        \"FilterExpression\": None,\n        \"Page\": 0,\n        \"TotalCount\": -1,\n        \"SortOrder\": \"desc\",\n        \"SortIndicator\": \"chevron-up\",\n        \"TimeZone\": \"America/Chicago\",\n        \"IsCommonUI\": False,\n        \"ComponentShortName\": None,\n        \"EnableMaxCountLimit\": True,\n        \"MaxCountLimit\": 1000,\n        \"ComponentName\": \"com-manh-cp-xint\",\n        \"Size\": 100,\n        \"Sort\": \"OrderDate\"\n    }\n    \n    # Customize payload based on report configuration\n    if report_config:\n        # Set request fields if specified\n        if \"report_fields\" in report_config:\n            payload[\"RequestAttributeIds\"] = report_config[\"report_fields\"]\n            \n        # Set view name if specified\n        view_name = report_config.get(\"query_parameters\", {}).get(\"view_name\")\n        if view_name:\n            payload[\"ViewName\"] = view_name\n            payload[\"Filters\"][0][\"ViewName\"] = view_name\n            \n        # Set sort field if specified\n        sort_field = report_config.get(\"query_parameters\", {}).get(\"sort_field\")\n        if sort_field:\n            payload[\"Sort\"] = sort_field\n            \n        # Add order type filter if specified\n        order_type = report_config.get(\"query_parameters\", {}).get(\"order_type\")\n        if order_type:\n            payload[\"Filters\"].append({\n                \"ViewName\": payload[\"ViewName\"],\n                \"AttributeId\": \"TextSearch\",\n                \"DataType\": \"text\",\n                \"requiredFilter\": False,\n                \"FilterValues\": [\n                    f\"\\\"{order_type}\\\"\"\n                ],\n                \"negativeFilter\": False\n            })\n    \n    # Set headers with authentication\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {token}\"\n    }\n    \n    all_results = []\n    page = 0\n    \n    try:\n        while True:\n            payload[\"Page\"] = page\n            logger.info(f\"Searching page {page}...\")\n            \n            response = requests.post(\n                search_endpoint, \n                json=payload,\n                headers=headers\n            )\n            \n            if response.status_code != 200:\n                logger.error(f\"Error in API call: {response.status_code} - {response.text}\")\n                raise Exception(f\"API returned error: {response.status_code}\")\n            \n            result_data = response.json()\n            \n            # Check if we have results\n            if not result_data.get(\"data\") or len(result_data[\"data\"]) == 0:\n                logger.info(f\"No more results found after page {page}\")\n                break\n            \n            all_results.extend(result_data[\"data\"])\n            logger.info(f\"Retrieved {len(result_data['data'])} records from page {page}\")\n            \n            # Check if we've reached the end\n            if len(all_results) >= result_data.get(\"totalCount\", 0) or len(result_data[\"data\"]) < payload[\"Size\"]:\n                break\n            \n            page += 1\n    \n    except Exception as e:\n        logger.error(f\"Error during API search: {str(e)}\")\n        raise\n    \n    logger.info(f\"Total records retrieved: {len(all_results)}\")\n    \n    # Log the API response to MongoDB if available\n    if mongo_available:\n        try:\n            report_id = report_config.get(\"report_id\") if report_config else None\n            query_params = {\n                \"from_date\": from_date,\n                \"to_date\": to_date,\n                \"report_config\": {\n                    \"report_id\": report_id,\n                    \"view_name\": payload.get(\"ViewName\"),\n                    \"sort_field\": payload.get(\"Sort\"),\n                    \"filters\": payload.get(\"Filters\")\n                }\n            }\n            \n            # Log to MongoDB and get the MongoDB document ID\n            mongo_doc_id = log_api_response(all_results, report_id, query_params)\n            if mongo_doc_id:\n                logger.info(f\"API response logged to MongoDB with ID: {mongo_doc_id}\")\n                \n                # Store the MongoDB document ID in a Variable for potential reuse\n                if report_id:\n                    Variable.set(f\"last_response_{report_id}\", mongo_doc_id)\n            else:\n                logger.warning(\"Failed to log API response to MongoDB\")\n        except Exception as e:\n            logger.error(f\"Error logging API response to MongoDB: {str(e)}\")\n            # Continue execution even if MongoDB logging fails\n    \n    return all_results","size_bytes":6590},"main.py":{"content":"def main():\n    print(\"Hello from repl-nix-workspace!\")\n\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":96},"airflow_home/webserver_config.py":{"content":"#\n# Licensed to the Apache Software Foundation (ASF) under one\n# or more contributor license agreements.  See the NOTICE file\n# distributed with this work for additional information\n# regarding copyright ownership.  The ASF licenses this file\n# to you under the Apache License, Version 2.0 (the\n# \"License\"); you may not use this file except in compliance\n# with the License.  You may obtain a copy of the License at\n#\n#   http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing,\n# software distributed under the License is distributed on an\n# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n# KIND, either express or implied.  See the License for the\n# specific language governing permissions and limitations\n# under the License.\n\"\"\"Default configuration for the Airflow webserver.\"\"\"\nfrom __future__ import annotations\n\nimport os\n\nfrom airflow.www.fab_security.manager import AUTH_DB\n\n# from airflow.www.fab_security.manager import AUTH_LDAP\n# from airflow.www.fab_security.manager import AUTH_OAUTH\n# from airflow.www.fab_security.manager import AUTH_OID\n# from airflow.www.fab_security.manager import AUTH_REMOTE_USER\n\n\nbasedir = os.path.abspath(os.path.dirname(__file__))\n\n# Flask-WTF flag for CSRF\nWTF_CSRF_ENABLED = True\nWTF_CSRF_TIME_LIMIT = None\n\n# ----------------------------------------------------\n# AUTHENTICATION CONFIG\n# ----------------------------------------------------\n# For details on how to set up each of the following authentication, see\n# http://flask-appbuilder.readthedocs.io/en/latest/security.html# authentication-methods\n# for details.\n\n# The authentication type\n# AUTH_OID : Is for OpenID\n# AUTH_DB : Is for database\n# AUTH_LDAP : Is for LDAP\n# AUTH_REMOTE_USER : Is for using REMOTE_USER from web server\n# AUTH_OAUTH : Is for OAuth\nAUTH_TYPE = AUTH_DB\n\n# Uncomment to setup Full admin role name\n# AUTH_ROLE_ADMIN = 'Admin'\n\n# Uncomment and set to desired role to enable access without authentication\n# AUTH_ROLE_PUBLIC = 'Viewer'\n\n# Will allow user self registration\n# AUTH_USER_REGISTRATION = True\n\n# The recaptcha it's automatically enabled for user self registration is active and the keys are necessary\n# RECAPTCHA_PRIVATE_KEY = PRIVATE_KEY\n# RECAPTCHA_PUBLIC_KEY = PUBLIC_KEY\n\n# Config for Flask-Mail necessary for user self registration\n# MAIL_SERVER = 'smtp.gmail.com'\n# MAIL_USE_TLS = True\n# MAIL_USERNAME = 'yourappemail@gmail.com'\n# MAIL_PASSWORD = 'passwordformail'\n# MAIL_DEFAULT_SENDER = 'sender@gmail.com'\n\n# The default user self registration role\n# AUTH_USER_REGISTRATION_ROLE = \"Public\"\n\n# When using OAuth Auth, uncomment to setup provider(s) info\n# Google OAuth example:\n# OAUTH_PROVIDERS = [{\n#   'name':'google',\n#     'token_key':'access_token',\n#     'icon':'fa-google',\n#         'remote_app': {\n#             'api_base_url':'https://www.googleapis.com/oauth2/v2/',\n#             'client_kwargs':{\n#                 'scope': 'email profile'\n#             },\n#             'access_token_url':'https://accounts.google.com/o/oauth2/token',\n#             'authorize_url':'https://accounts.google.com/o/oauth2/auth',\n#             'request_token_url': None,\n#             'client_id': GOOGLE_KEY,\n#             'client_secret': GOOGLE_SECRET_KEY,\n#         }\n# }]\n\n# When using LDAP Auth, setup the ldap server\n# AUTH_LDAP_SERVER = \"ldap://ldapserver.new\"\n\n# When using OpenID Auth, uncomment to setup OpenID providers.\n# example for OpenID authentication\n# OPENID_PROVIDERS = [\n#    { 'name': 'Yahoo', 'url': 'https://me.yahoo.com' },\n#    { 'name': 'AOL', 'url': 'http://openid.aol.com/<username>' },\n#    { 'name': 'Flickr', 'url': 'http://www.flickr.com/<username>' },\n#    { 'name': 'MyOpenID', 'url': 'https://www.myopenid.com' }]\n\n# ----------------------------------------------------\n# Theme CONFIG\n# ----------------------------------------------------\n# Flask App Builder comes up with a number of predefined themes\n# that you can use for Apache Airflow.\n# http://flask-appbuilder.readthedocs.io/en/latest/customizing.html#changing-themes\n# Please make sure to remove \"navbar_color\" configuration from airflow.cfg\n# in order to fully utilize the theme. (or use that property in conjunction with theme)\n# APP_THEME = \"bootstrap-theme.css\"  # default bootstrap\n# APP_THEME = \"amelia.css\"\n# APP_THEME = \"cerulean.css\"\n# APP_THEME = \"cosmo.css\"\n# APP_THEME = \"cyborg.css\"\n# APP_THEME = \"darkly.css\"\n# APP_THEME = \"flatly.css\"\n# APP_THEME = \"journal.css\"\n# APP_THEME = \"lumen.css\"\n# APP_THEME = \"paper.css\"\n# APP_THEME = \"readable.css\"\n# APP_THEME = \"sandstone.css\"\n# APP_THEME = \"simplex.css\"\n# APP_THEME = \"slate.css\"\n# APP_THEME = \"solar.css\"\n# APP_THEME = \"spacelab.css\"\n# APP_THEME = \"superhero.css\"\n# APP_THEME = \"united.css\"\n# APP_THEME = \"yeti.css\"\n","size_bytes":4771},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"apache-airflow==2.7.2\",\n    \"bcrypt>=5.0.0\",\n    \"matplotlib>=3.10.7\",\n    \"oracledb>=3.4.1\",\n    \"pandas>=2.3.3\",\n    \"psycopg2-binary>=2.9.11\",\n    \"pymongo>=4.15.4\",\n    \"reportlab>=4.4.5\",\n    \"requests>=2.32.5\",\n]\n","size_bytes":366}},"version":2}